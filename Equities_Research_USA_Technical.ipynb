{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Windows async policy set\n",
      "âœ… yahooquery loaded\n",
      "âœ… yfinance loaded\n",
      "\n",
      "ðŸŽ‰ All imports complete!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: IMPORTS WITH WINDOWS/VPN FIXES\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress noisy warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === WINDOWS ASYNC FIX ===\n",
    "if sys.platform == \"win32\":\n",
    "    import asyncio\n",
    "\n",
    "    try:\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "        print(\"âœ… Windows async policy set\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Async policy warning: {e}\")\n",
    "\n",
    "# === SSL/VPN FIXES ===\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONHTTPSVERIFY\"] = \"0\"\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# === MAIN IMPORTS ===\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# === YAHOO IMPORTS (with error handling) ===\n",
    "try:\n",
    "    from yahooquery import Ticker\n",
    "\n",
    "    print(\"âœ… yahooquery loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ yahooquery failed: {e}\")\n",
    "    Ticker = None\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "\n",
    "    print(\"âœ… yfinance loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ yfinance failed: {e}\")\n",
    "    yf = None\n",
    "\n",
    "from src.setup import *\n",
    "from src.fetch import get_combined_universe\n",
    "\n",
    "print(\"\\nðŸŽ‰ All imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38cad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PRICE = 2.00  # Stock price must be at least $2 (avoid \"penny stocks\")\n",
    "MIN_VOLUME = 1_000_000  # At least 1,000,000 shares traded per day (on average)\n",
    "\n",
    "MIN_CAP = 300_000_000  # Market cap at least $300 million (company value)\n",
    "# Market Cap = Stock Price Ã— Number of Shares\n",
    "MIN_CURRENT_RATIO = 1.2  # Current Ratio must be > 1.2\n",
    "# Current Ratio = Current Assets / Current Liabilities\n",
    "# If > 1, the company can pay its short-term bills\n",
    "MAX_PE_RATIO = 100.0  # P/E ratio must be less than 100\n",
    "# P/E = Price / Earnings Per Share\n",
    "\n",
    "\n",
    "# 4. SAFETY THRESHOLDS - Additional quality filters\n",
    "# -------------------------------------------------\n",
    "MIN_INTEREST_COVERAGE = (\n",
    "    1.5  # Interest Coverage > 1.5 means company earns 1.5x what it owes in interest\n",
    ")\n",
    "# Interest Coverage = EBIT / Interest Expense\n",
    "# If < 1, company can't pay its interest bills = bad!\n",
    "MIN_ROIC = 0.05  # ROIC (Return on Invested Capital) > 5%\n",
    "# ROIC = Operating Profit / Capital Invested\n",
    "# Shows how well management uses money to generate returns\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # Operating Margin > 5% for \"Fortress\" (best) tier\n",
    "# Operating Margin = Operating Income / Revenue\n",
    "# Shows what % of sales becomes actual profit\n",
    "\n",
    "# Sectors we want to EXCLUDE (skip)\n",
    "# Financial Services and Real Estate have very different financial structures\n",
    "EXCLUDED_SECTORS = [\"Financial Services\", \"Real Estate\"]\n",
    "\n",
    "CACHE_EXPIRY_DAYS = 30  # Re-fetch data if our saved data is older than 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching North American Universe ---\n",
      "   -> Found 6008 US stocks.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 6008 stocks ---\n",
      " -> Processing Batch 1/13...\n",
      " -> Processing Batch 6/13...\n",
      " -> Processing Batch 11/13...\n",
      "\n",
      " Step 2 Complete. 554 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 554 Survivors ---\n",
      " -> Analyzing 1/554: A...\n",
      " -> Analyzing 21/554: ALGN...\n",
      " -> Analyzing 41/554: AQN...\n",
      " -> Analyzing 61/554: AXL...\n",
      " -> Analyzing 81/554: BMY...\n",
      " -> Analyzing 101/554: CCC...\n",
      " -> Analyzing 121/554: CNXC...\n",
      " -> Analyzing 141/554: CXM...\n",
      " -> Analyzing 161/554: DT...\n",
      " -> Analyzing 181/554: ETN...\n",
      " -> Analyzing 201/554: FOLD...\n",
      " -> Analyzing 221/554: GIL...\n",
      " -> Analyzing 241/554: HALO...\n",
      " -> Analyzing 261/554: HSY...\n",
      " -> Analyzing 281/554: ITGR...\n",
      " -> Analyzing 301/554: LFST...\n",
      " -> Analyzing 321/554: MHK...\n",
      " -> Analyzing 341/554: NFLX...\n",
      " -> Analyzing 361/554: OLLI...\n",
      " -> Analyzing 381/554: PGY...\n",
      " -> Analyzing 401/554: QXO...\n",
      " -> Analyzing 421/554: RVTY...\n",
      " -> Analyzing 441/554: SMCI...\n",
      " -> Analyzing 461/554: STZ...\n",
      " -> Analyzing 481/554: TOL...\n",
      " -> Analyzing 501/554: ULS...\n",
      " -> Analyzing 521/554: VSAT...\n",
      " -> Analyzing 541/554: XPRO...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (220): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (107): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (223): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "    Ticker      Tier    Price    P/E                  Sector  Z-Score  ROIC %  Op Margin %  Avg Margin (4Y)  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "530    WPM  Fortress  135.350  61.24         Basic Materials   224.89    8.72        66.54            50.89       8.089  2269.82        61.53\n",
      "344   NVDA  Fortress  186.105  46.07              Technology    89.42   90.08        63.17            43.63       4.468   341.19      4531.10\n",
      "276   ISRG  Fortress  535.068  70.96              Healthcare    53.70   13.82        30.33            27.54       4.728   100.00       191.81\n",
      "404   RGLD  Fortress  265.120  36.37         Basic Materials    52.53   13.18        50.53            51.72       3.516    44.71        22.38\n",
      "408   RMBS  Fortress  107.990  51.42              Technology    32.66   15.97        35.43            19.68      11.609   142.27        11.63\n",
      "184   FAST  Fortress   43.740  41.26             Industrials    32.25   37.78        20.70            20.47       4.259   207.59        50.22\n",
      "123   CPRT  Fortress   41.040  25.18             Industrials    29.73   18.04        37.29            37.83       7.939      NaN        39.73\n",
      "320   MNST  Fortress   78.170  44.41      Consumer Defensive    29.56   29.15        30.74            27.67       3.185   100.00        76.37\n",
      "47     ASM  Fortress    7.040  50.29         Basic Materials    28.88   11.12        32.56             6.68       2.754    38.26         1.10\n",
      "153   DOCS  Fortress   41.260  33.01              Healthcare    27.80   20.77        38.55            34.85       7.786   100.00         7.77\n",
      "29    ANET  Fortress  129.830  49.18              Technology    26.95   26.03        42.38            36.70       3.254   100.00       163.49\n",
      "466    TER  Fortress  228.145  82.66              Technology    26.54   19.87        18.89            24.67       1.759   170.80        36.29\n",
      "35     APP  Fortress  568.760  67.15  Communication Services    26.42   39.37        76.80            15.80       3.250     5.95       192.38\n",
      "229   GOOG  Fortress  330.340  32.58  Communication Services    21.73   33.25        30.51            29.14       1.747   448.07      3987.81\n",
      "483   TSEM  Fortress  129.830  75.05              Technology    21.48    7.92        12.78            14.02       6.610    54.97        14.60\n"
     ]
    }
   ],
   "source": [
    "from src.filters import get_initial_survivors\n",
    "from src.financial_analysis import get_advanced_metrics\n",
    "\n",
    "# STEP 1: Get list of all US stocks\n",
    "tickers = get_combined_universe()\n",
    "\n",
    "if len(tickers) > 0:\n",
    "    # STEP 2: Apply quick filters\n",
    "    survivors_df = get_initial_survivors(\n",
    "        tickers,\n",
    "        MIN_PRICE,\n",
    "        MIN_VOLUME,\n",
    "        MIN_CAP,\n",
    "        MIN_CURRENT_RATIO,\n",
    "        EXCLUDED_SECTORS,\n",
    "        MAX_PE_RATIO,\n",
    "    )\n",
    "\n",
    "    if not survivors_df.empty:\n",
    "        print(f\"\\n Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "\n",
    "        # STEP 3: Deep financial analysis\n",
    "        final_results = get_advanced_metrics(survivors_df, CACHE_EXPIRY_DAYS,FORTRESS_MARGIN_THRESHOLD,MIN_INTEREST_COVERAGE,MIN_ROIC,calculate_altman_z_yfinance,save_cache)\n",
    "\n",
    "        if not final_results.empty:\n",
    "            # Sort results: First by Tier (alphabetically), then by Z-Score (highest first)\n",
    "            final_results = final_results.sort_values(\n",
    "                by=[\"Tier\", \"Z-Score\"],\n",
    "                ascending=[True, False],  # True = A-Z, False = highest first\n",
    "            )\n",
    "\n",
    "            # Split into three categories based on tier\n",
    "            fortress_df = final_results[final_results[\"Tier\"] == \"Fortress\"].copy()\n",
    "            strong_df = final_results[final_results[\"Tier\"] == \"Strong\"].copy()\n",
    "            risky_df = final_results[final_results[\"Tier\"] == \"Risky\"].copy()\n",
    "\n",
    "            # Save to CSV files (spreadsheet format)\n",
    "            try:\n",
    "                fortress_df.to_csv(\n",
    "                    FORTRESS_CSV, index=False\n",
    "                )  # index=False means don't save row numbers\n",
    "                strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                risky_df.to_csv(RISKY_CSV, index=False)\n",
    "\n",
    "                print(\"\\n\" + \"=\" * 60)\n",
    "                print(\"RESULTS GENERATED\")\n",
    "                print(\"=\" * 60)\n",
    "                print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error Saving Files: {e}\")\n",
    "\n",
    "            # Set display options for pandas (so we can see more data)\n",
    "            pd.set_option(\"display.max_rows\", 500)\n",
    "            pd.set_option(\"display.max_columns\", 20)\n",
    "            pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "            # Show preview of fortress stocks\n",
    "            print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "            print(fortress_df.head(15))  # .head(15) shows first 15 rows\n",
    "        else:\n",
    "            print(\"No stocks passed the deep financial analysis.\")\n",
    "    else:\n",
    "        print(\"No stocks passed the initial lightweight filter.\")\n",
    "else:\n",
    "    print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3723f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FORTRESS PULLBACK: Scanning 220 stocks (RSI < 40) ---\n",
      "\n",
      "SUCCESS: Pullback candidates saved to 'YfinanceDataDump/Fortress_Pullback_Candidates_USA.csv'\n",
      "Original Fortress Count: 220 -> Pullback Count: 10\n",
      "\n",
      "--- FORTRESS STOCKS 'ON SALE' ---\n",
      "  Ticker    Price  RSI_14  SMA_200  Dist_to_SMA_%      Tier\n",
      "7   WLTH    9.500   14.38      NaN            NaN  Fortress\n",
      "8   VSNT   33.040   22.74      NaN            NaN  Fortress\n",
      "5   QCOM  159.420   32.30   158.62           0.50  Fortress\n",
      "0   ISRG  535.068   34.70   514.74           3.94  Fortress\n",
      "3   NBIX  132.390   35.37   132.19           0.15  Fortress\n",
      "4    ULS   75.000   35.38    71.79           4.47  Fortress\n",
      "1    APP  568.760   35.68   482.72          17.82  Fortress\n",
      "9   TGNA   18.850   36.52    18.35           2.73  Fortress\n",
      "2     ZM   80.960   36.79    80.14           1.03  Fortress\n",
      "6   URBN   69.480   38.30    68.67           1.17  Fortress\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6a: FORTRESS PULLBACK SCAN (RSI + TREND)\n",
    "# =============================================================================\n",
    "# This scan looks for high-quality \"Fortress\" stocks that are:\n",
    "# 1. In a long-term Uptrend (Price > 200 SMA)\n",
    "# 2. In a short-term Pullback (RSI < 40)\n",
    "# This is the \"Buy the Dip\" strategy for quality assets.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_fortress_pullback(df_input, rsi_threshold=40):\n",
    "    \"\"\"\n",
    "    Calculates RSI (14-day) and 200-day SMA.\n",
    "    Filters for stocks where Price > SMA200 AND RSI < Threshold.\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Fortress Pullback] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(\n",
    "        f\"\\n--- FORTRESS PULLBACK: Scanning {len(tickers)} stocks (RSI < {rsi_threshold}) ---\"\n",
    "    )\n",
    "\n",
    "    # 1. Fetch History (Need ~1 year for SMA 200)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pullback_candidates = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle Data Structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need enough data\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history.\")\n",
    "                continue\n",
    "\n",
    "            # 2. Calculate 200-Day SMA (Trend Filter)\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # CONDITION 1: Must be in an Uptrend\n",
    "            if current_price < sma_200:\n",
    "                continue\n",
    "\n",
    "            # 3. Calculate RSI (14-Day)\n",
    "            # Calculate daily price changes\n",
    "            delta = df_hist[\"Close\"].diff()\n",
    "\n",
    "            # Separate gains and losses\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "            # Calculate Exponential Moving Average (Wilder's Smoothing usually uses alpha=1/14)\n",
    "            avg_gain = gain.ewm(com=13, adjust=False).mean()\n",
    "            avg_loss = loss.ewm(com=13, adjust=False).mean()\n",
    "\n",
    "            # Calculate RS and RSI\n",
    "            rs = avg_gain / avg_loss\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "            current_rsi = rsi.iloc[-1]\n",
    "\n",
    "            # CONDITION 2: Must be Oversold (Pullback)\n",
    "            if current_rsi < rsi_threshold:\n",
    "                # Get base data\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                base_row[\"RSI_14\"] = round(current_rsi, 2)\n",
    "                base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "                # Distance from SMA (Buy Zone Depth)\n",
    "                base_row[\"Dist_to_SMA_%\"] = round(\n",
    "                    ((current_price - sma_200) / sma_200) * 100, 2\n",
    "                )\n",
    "\n",
    "                pullback_candidates.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(pullback_candidates)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# Check if Fortress DataFrame exists\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "\n",
    "    # Run the scan\n",
    "    # We use 40 as the threshold because quality stocks rarely drop to 30\n",
    "    Fortress_Dip_DF = apply_fortress_pullback(fortress_df, rsi_threshold=40)\n",
    "\n",
    "    if not Fortress_Dip_DF.empty:\n",
    "        # Sort by Lowest RSI (Deepest Dip)\n",
    "        Fortress_Dip_DF = Fortress_Dip_DF.sort_values(by=\"RSI_14\", ascending=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        PULLBACK_CSV = \"YfinanceDataDump/Fortress_Pullback_Candidates_USA.csv\"\n",
    "        Fortress_Dip_DF.to_csv(PULLBACK_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Pullback candidates saved to '{PULLBACK_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Fortress Count: {len(fortress_df)} -> Pullback Count: {len(Fortress_Dip_DF)}\"\n",
    "        )\n",
    "\n",
    "        cols = [\"Ticker\", \"Price\", \"RSI_14\", \"SMA_200\", \"Dist_to_SMA_%\", \"Tier\"]\n",
    "        print(\"\\n--- FORTRESS STOCKS 'ON SALE' ---\")\n",
    "        print(Fortress_Dip_DF[cols].head(15))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. No Fortress stocks are currently oversold (RSI < 40).\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Error: 'fortress_df' not found. Please run the Main Execution cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 220 Stocks ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/220: WPM...\n",
      " -> Analyst Scan 11/220: ANET...\n",
      " -> Analyst Scan 21/220: CPRX...\n",
      " -> Analyst Scan 31/220: META...\n",
      " -> Analyst Scan 41/220: LLY...\n",
      " -> Analyst Scan 51/220: TXN...\n",
      " -> Analyst Scan 61/220: REGN...\n",
      " -> Analyst Scan 71/220: AEM...\n",
      " -> Analyst Scan 81/220: ULS...\n",
      " -> Analyst Scan 91/220: PAAS...\n",
      " -> Analyst Scan 101/220: ABT...\n",
      " -> Analyst Scan 111/220: ECL...\n",
      " -> Analyst Scan 121/220: LRN...\n",
      " -> Analyst Scan 131/220: ATI...\n",
      " -> Analyst Scan 141/220: DKS...\n",
      " -> Analyst Scan 151/220: GNRC...\n",
      " -> Analyst Scan 161/220: TOL...\n",
      " -> Analyst Scan 171/220: TMHC...\n",
      " -> Analyst Scan 181/220: TPR...\n",
      " -> Analyst Scan 191/220: BLDR...\n",
      " -> Analyst Scan 201/220: BURL...\n",
      " -> Analyst Scan 211/220: BIRK...\n",
      "\n",
      "  Analyst Scan Complete!\n",
      "Found 186 stocks with Buy Ratings (Score < 2.5)\n",
      "Saved to 'YfinanceDataDump\\Analyst_Fortress_Picks.csv'\n",
      "    Ticker    Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "16    CORT   34.730         2.16667    162.02     91.000000  Fortress\n",
      "46    SGHC    9.940         1.25000     77.31     17.625000  Fortress\n",
      "147   WLTH    9.500         2.14286     73.68     16.500000  Fortress\n",
      "124    TTD   35.477         2.13158     67.71     59.500000  Fortress\n",
      "7     DOCS   41.260         1.95000     57.78     65.100000  Fortress\n",
      "179   BIRK   38.470         1.56522     54.99     59.623337  Fortress\n",
      "83    BRBR   23.910         1.73333     53.85     36.785710  Fortress\n",
      "17    CPRX   22.700         1.00000     53.56     34.857140  Fortress\n",
      "104    LRN   69.710         2.00000     50.62    105.000000  Fortress\n",
      "88      DT   39.880         1.60000     48.27     59.129030  Fortress\n",
      "61    INTU  545.290         1.71429     45.44    793.050600  Fortress\n",
      "102    BSX   88.070         1.26471     41.26    124.406250  Fortress\n",
      "176    PDD  106.703         1.75610     39.87    149.248600  Fortress\n",
      "36    NFLX   88.000         1.91111     39.72    122.957250  Fortress\n",
      "15    VEEV  222.210         2.00000     39.33    309.610000  Fortress\n",
      "67    ALKS   31.630         1.52941     38.12     43.687500  Fortress\n",
      "64    VNOM   36.940         1.38889     37.31     50.722220  Fortress\n",
      "169   SMPL   20.930         2.00000     36.17     28.500000  Fortress\n",
      "1     NVDA  186.105         1.34375     35.95    253.017930  Fortress\n",
      "45    NBIX  132.390         1.44444     35.65    179.589260  Fortress\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: STEP 4 - ANALYST RATINGS FILTER\n",
    "# =============================================================================\n",
    "# This adds another layer of analysis: what do professional analysts think?\n",
    "# Analyst Rating Scale (typically):\n",
    "#   1.0 = Strong Buy\n",
    "#   2.0 = Buy\n",
    "#   3.0 = Hold\n",
    "#   4.0 = Sell\n",
    "#   5.0 = Strong Sell\n",
    "\n",
    "\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    \"\"\"\n",
    "    Fetch analyst ratings for stocks and filter for those rated \"Buy\" or better.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks with analyst ratings and upside potential\n",
    "    \"\"\"\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df[\"Ticker\"].tolist()\n",
    "\n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "\n",
    "    analyst_data = []\n",
    "\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        # Print progress every 10 stocks\n",
    "        if i % 10 == 0:\n",
    "            print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info  # Get all available info for the stock\n",
    "\n",
    "            # Extract analyst recommendation (1.0 to 5.0 scale)\n",
    "            rec_mean = info.get(\"recommendationMean\")\n",
    "            target_price = info.get(\"targetMeanPrice\")  # Average price target\n",
    "            current_price = info.get(\"currentPrice\")\n",
    "\n",
    "            # Filter: Only keep stocks rated 2.5 or better (Buy or Strong Buy)\n",
    "            if rec_mean is None or rec_mean > 2.5:\n",
    "                continue\n",
    "\n",
    "            # Calculate upside potential\n",
    "            # Upside = (Target - Current) / Current * 100\n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(\n",
    "                    ((target_price - current_price) / current_price) * 100, 2\n",
    "                )\n",
    "\n",
    "            # Get the original data and add new columns\n",
    "            base_row = working_df[working_df[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "            base_row[\"Analyst_Rating\"] = rec_mean\n",
    "            base_row[\"Target_Price\"] = target_price\n",
    "            base_row[\"Upside_%\"] = upside\n",
    "\n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2)  # Small delay to not be timed out of Yahoo's servers\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTE THE ANALYST FILTER\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "\n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "\n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by highest upside potential\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(\n",
    "            by=\"Upside_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        print(\"\\n  Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.5)\")\n",
    "\n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(f\"Saved to '{ANALYST_CSV}'\")\n",
    "\n",
    "        # Show top picks\n",
    "        cols = [\"Ticker\", \"Price\", \"Analyst_Rating\", \"Upside_%\", \"Target_Price\", \"Tier\"]\n",
    "        print(Analyst_Fortress_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"  'fortress_df' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 550 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "============================================================\n",
      "BUFFETT SCAN COMPLETE\n",
      "============================================================\n",
      "Found 18 Deep Value Stocks\n",
      "\n",
      "--- DEEP VALUE PICKS ---\n",
      "   Ticker   Price  P/B Ratio  ROE %  Debt/Eq %                  Sector      Tier\n",
      "9    ACHC   11.68       0.34   3.69      74.49              Healthcare     Risky\n",
      "0    GMAB   32.25       0.35  29.41       2.47              Healthcare  Fortress\n",
      "8      KT   19.49       0.40   5.08      60.17  Communication Services     Risky\n",
      "5     SSL    6.31       0.44   5.07      76.56         Basic Materials     Risky\n",
      "7    ANGI   12.49       0.55   3.42      54.03  Communication Services     Risky\n",
      "4     HLX    7.09       0.66   2.71      39.52                  Energy     Risky\n",
      "15     WB   10.75       0.67  12.37      47.28  Communication Services    Strong\n",
      "13     MT   48.73       0.68   4.72      26.23         Basic Materials    Strong\n",
      "16   MOMO    6.99       0.68   6.72       1.43  Communication Services    Strong\n",
      "10     DD   42.86       0.78   3.22      39.67         Basic Materials     Risky\n",
      "17    GGB    4.16       0.81   5.51      36.52         Basic Materials    Strong\n",
      "12    MHK  122.84       0.91   5.20      28.03       Consumer Cyclical    Strong\n",
      "3    DINO   48.63       0.95   4.18      35.77                  Energy     Risky\n",
      "6    SBLK   20.37       0.96   2.50      50.95             Industrials     Risky\n",
      "14    SXC    7.91       0.96  10.23      97.59         Basic Materials    Strong\n",
      "2    TGNA   18.85       0.97  11.45      83.12  Communication Services  Fortress\n",
      "11    KBH   61.32       0.99  10.77      43.40       Consumer Cyclical     Risky\n",
      "1    TMHC   63.27       1.00  14.40      36.53       Consumer Cyclical  Fortress\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: BUFFETT VALUE SCAN\n",
    "# =============================================================================\n",
    "# This filter looks for stocks Warren Buffett might like:\n",
    "# - Trading BELOW book value (P/B < 1.0) means you're buying $1 of assets for less than $1\n",
    "# - Positive Return on Equity (ROE) shows the company is profitable\n",
    "# - Reasonable debt levels (Debt/Equity < 100%)\n",
    "\n",
    "\n",
    "def get_buffett_value_picks(df_input):\n",
    "    \"\"\"\n",
    "    Find deep value stocks trading below their book value.\n",
    "\n",
    "    Book Value = Total Assets - Total Liabilities\n",
    "    P/B Ratio = Stock Price / Book Value per Share\n",
    "\n",
    "    If P/B < 1.0, you're theoretically buying the company for less than\n",
    "    what it would be worth if you sold all its assets and paid all debts.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Deep value stocks sorted by P/B ratio\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\n",
    "        \"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\"\n",
    "    )\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Process in chunks for speed\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # Get key statistics and financial data\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get(\"defaultKeyStatistics\", {})\n",
    "                        fin = data[symbol].get(\"financialData\", {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core \"Value\" Rule)\n",
    "                        pb = stats.get(\"priceToBook\")\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0:\n",
    "                            continue\n",
    "\n",
    "                        # 2. Positive ROE (Return on Equity - company makes money)\n",
    "                        roe = fin.get(\"returnOnEquity\", 0)\n",
    "                        if roe is None or roe <= 0:\n",
    "                            continue\n",
    "\n",
    "                        # 3. Reasonable Debt (not overleveraged)\n",
    "                        de = fin.get(\"debtToEquity\", 0)\n",
    "                        if de is None or de > 100:\n",
    "                            continue\n",
    "\n",
    "                        # Get base data and add value metrics\n",
    "                        base_row = (\n",
    "                            df_input[df_input[\"Ticker\"] == symbol].iloc[0].to_dict()\n",
    "                        )\n",
    "                        base_row[\"P/B Ratio\"] = round(pb, 2)\n",
    "                        base_row[\"ROE %\"] = round(roe * 100, 2)\n",
    "                        base_row[\"Debt/Eq %\"] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except:\n",
    "                        continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "\n",
    "# Run the Buffett scan\n",
    "if \"final_results\" in locals() and not final_results.empty:\n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "\n",
    "    if not Buffett_Value_DF.empty:\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by=\"P/B Ratio\", ascending=True)\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks\")\n",
    "\n",
    "        cols = [\"Ticker\", \"Price\", \"P/B Ratio\", \"ROE %\", \"Debt/Eq %\", \"Sector\", \"Tier\"]\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head(20))\n",
    "    else:\n",
    "        print(\"\\n  No stocks passed the Buffett filter.\")\n",
    "else:\n",
    "    print(\" 'final_results' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca01e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TREND ALIGNMENT: Checking 200-Day SMA for 18 Buffett candidates ---\n",
      "\n",
      "SUCCESS: Filtered list saved to 'YfinanceDataDump/Buffett_Trend_Aligned_USA.csv'\n",
      "Original Count: 18 -> Trend Aligned Count: 15\n",
      "\n",
      "--- BUFFETT STOCKS IN UPTREND ---\n",
      "   Ticker   Price  P/B Ratio  SMA_200  Trend_Dist_%      Tier\n",
      "1      KT   19.49       0.40    19.26          1.17     Risky\n",
      "11    SXC    7.91       0.96     7.79          1.59    Strong\n",
      "14   TMHC   63.27       1.00    61.74          2.47  Fortress\n",
      "12   TGNA   18.85       0.97    18.35          2.73  Fortress\n",
      "13    KBH   61.32       0.99    58.20          5.37     Risky\n",
      "4      WB   10.75       0.67    10.18          5.56    Strong\n",
      "8     MHK  122.84       0.91   114.52          7.27    Strong\n",
      "3     HLX    7.09       0.66     6.53          8.50     Risky\n",
      "9    DINO   48.63       0.95    44.31          9.75     Risky\n",
      "2     SSL    6.31       0.44     5.51         14.47     Risky\n",
      "10   SBLK   20.37       0.96    17.74         14.82     Risky\n",
      "0    GMAB   32.25       0.35    25.88         24.61  Fortress\n",
      "6      DD   42.86       0.78    32.61         31.44     Risky\n",
      "7     GGB    4.16       0.81     3.13         32.94    Strong\n",
      "5      MT   48.73       0.68    35.37         37.77    Strong\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8a: BUFFETT TREND ALIGNMENT (200-DAY SMA)\n",
    "# =============================================================================\n",
    "# This cell takes the 'Deep Value' candidates found in the previous step and\n",
    "# filters out any that are in a long-term downtrend (Price < 200-Day SMA).\n",
    "# This helps avoid \"Value Traps\" - stocks that are cheap because they are dying.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_trend_alignment(df_input):\n",
    "    \"\"\"\n",
    "    Calculates the 200-day SMA and filters for stocks trading ABOVE it.\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Trend Alignment] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(\n",
    "        f\"\\n--- TREND ALIGNMENT: Checking 200-Day SMA for {len(tickers)} Buffett candidates ---\"\n",
    "    )\n",
    "\n",
    "    # 1. Fetch History (Need at least 200 trading days, so 1y is perfect)\n",
    "    try:\n",
    "        # group_by='ticker' ensures the dataframe structure is consistent\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    trend_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure: if multiple tickers, it uses MultiIndex\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                # If only one ticker, yfinance returns a flat dataframe\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need at least 200 days of data to calculate the SMA\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history (<200 days).\")\n",
    "                continue\n",
    "\n",
    "            # 2. Calculate 200-Day SMA\n",
    "            # .rolling(window=200).mean() averages the last 200 closing prices\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # 3. The Filter Condition: Price > SMA 200\n",
    "            # We want stocks that have \"reclaimed\" their trend\n",
    "            is_uptrend = current_price > sma_200\n",
    "\n",
    "            # Calculate how far above/below the SMA it is (as a %)\n",
    "            distance_pct = round(((current_price - sma_200) / sma_200) * 100, 2)\n",
    "\n",
    "            if is_uptrend:\n",
    "                # Get the original row data from the Buffett DataFrame\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                # Add technical metrics to the row\n",
    "                base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "                base_row[\"Trend_Dist_%\"] = distance_pct\n",
    "\n",
    "                trend_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Create the new filtered DataFrame\n",
    "    return pd.DataFrame(trend_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# Check if the Buffett DataFrame exists from the previous cell\n",
    "if \"Buffett_Value_DF\" in locals() and not Buffett_Value_DF.empty:\n",
    "\n",
    "    # Run the filter\n",
    "    Buffett_Trend_DF = apply_trend_alignment(Buffett_Value_DF)\n",
    "\n",
    "    if not Buffett_Trend_DF.empty:\n",
    "        # Sort by trend strength (how far above the 200 SMA they are)\n",
    "        Buffett_Trend_DF = Buffett_Trend_DF.sort_values(\n",
    "            by=\"Trend_Dist_%\", ascending=True\n",
    "        )\n",
    "\n",
    "        # Save to a new CSV\n",
    "        TREND_CSV = \"YfinanceDataDump/Buffett_Trend_Aligned_USA.csv\"\n",
    "        Buffett_Trend_DF.to_csv(TREND_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Filtered list saved to '{TREND_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Count: {len(Buffett_Value_DF)} -> Trend Aligned Count: {len(Buffett_Trend_DF)}\"\n",
    "        )\n",
    "\n",
    "        # Display the survivors\n",
    "        cols = [\"Ticker\", \"Price\", \"P/B Ratio\", \"SMA_200\", \"Trend_Dist_%\", \"Tier\"]\n",
    "        print(\"\\n--- BUFFETT STOCKS IN UPTREND ---\")\n",
    "        print(Buffett_Trend_DF[cols].head(15))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. All Buffett picks are currently in a downtrend.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Error: 'Buffett_Value_DF' not found. Please run the Buffett Scan cell first.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065392ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scanning 220 stocks for Insider Buying...\n",
      "Created 'Fortress_insiders' with 12 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "45edd603-2532-45c5-b0e1-e10592a90afb",
       "rows": [
        [
         "0",
         "MU",
         "362.75",
         "3",
         "167433.0"
        ],
        [
         "1",
         "CDE",
         "22.58",
         "21",
         "1650770.0"
        ],
        [
         "2",
         "HXL",
         "82.59",
         "6",
         "14327.0"
        ],
        [
         "3",
         "GIL",
         "63.22",
         "105",
         "1426104.0"
        ],
        [
         "4",
         "SHLS",
         "9.27",
         "3",
         "8335.0"
        ],
        [
         "5",
         "CGAU",
         "16.13",
         "87",
         "4297682.0"
        ],
        [
         "6",
         "RAL",
         "53.53",
         "1",
         "2000.0"
        ],
        [
         "7",
         "TTD",
         "35.477",
         "10",
         "3557415.0"
        ],
        [
         "8",
         "FSM",
         "10.42",
         "10",
         "2116207.0"
        ],
        [
         "9",
         "OPCH",
         "36.03",
         "8",
         "18954.0"
        ],
        [
         "10",
         "CRH",
         "122.97",
         "3",
         "413316.0"
        ],
        [
         "11",
         "HSIC",
         "79.98",
         "5",
         "16257.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MU</td>\n",
       "      <td>362.750</td>\n",
       "      <td>3</td>\n",
       "      <td>167433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDE</td>\n",
       "      <td>22.580</td>\n",
       "      <td>21</td>\n",
       "      <td>1650770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HXL</td>\n",
       "      <td>82.590</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIL</td>\n",
       "      <td>63.220</td>\n",
       "      <td>105</td>\n",
       "      <td>1426104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>9.270</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CGAU</td>\n",
       "      <td>16.130</td>\n",
       "      <td>87</td>\n",
       "      <td>4297682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RAL</td>\n",
       "      <td>53.530</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TTD</td>\n",
       "      <td>35.477</td>\n",
       "      <td>10</td>\n",
       "      <td>3557415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FSM</td>\n",
       "      <td>10.420</td>\n",
       "      <td>10</td>\n",
       "      <td>2116207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPCH</td>\n",
       "      <td>36.030</td>\n",
       "      <td>8</td>\n",
       "      <td>18954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CRH</td>\n",
       "      <td>122.970</td>\n",
       "      <td>3</td>\n",
       "      <td>413316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HSIC</td>\n",
       "      <td>79.980</td>\n",
       "      <td>5</td>\n",
       "      <td>16257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0      MU        362.750                   3           167433.0\n",
       "1     CDE         22.580                  21          1650770.0\n",
       "2     HXL         82.590                   6            14327.0\n",
       "3     GIL         63.220                 105          1426104.0\n",
       "4    SHLS          9.270                   3             8335.0\n",
       "5    CGAU         16.130                  87          4297682.0\n",
       "6     RAL         53.530                   1             2000.0\n",
       "7     TTD         35.477                  10          3557415.0\n",
       "8     FSM         10.420                  10          2116207.0\n",
       "9    OPCH         36.030                   8            18954.0\n",
       "10    CRH        122.970                   3           413316.0\n",
       "11   HSIC         79.980                   5            16257.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: INSIDER TRADING FILTER\n",
    "# =============================================================================\n",
    "# Insiders (executives, directors, major shareholders) sometimes have better\n",
    "# information about their company. When they BUY their own stock, it can be\n",
    "# a positive sign. When they SELL, it might be neutral (paying taxes) or negative.\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def filter_for_insider_buying(tickers):\n",
    "    \"\"\"\n",
    "    Find stocks where company insiders are NET BUYERS.\n",
    "\n",
    "    Net Buying = Total shares bought - Total shares sold\n",
    "    If positive, insiders are accumulating shares (bullish signal).\n",
    "\n",
    "    Args:\n",
    "        tickers: List of stock symbols to check\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks with positive insider buying\n",
    "    \"\"\"\n",
    "    print(f\" Scanning {len(tickers)} stocks for Insider Buying...\")\n",
    "    insider_picks = []\n",
    "\n",
    "    # Process in smaller chunks to avoid timeout\n",
    "    chunk_size = 25\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "\n",
    "            # Fetch insider transaction data\n",
    "            df_insiders = yq.insider_transactions\n",
    "\n",
    "            # Fetch current prices\n",
    "            price_data = yq.price\n",
    "\n",
    "            # Skip if no data\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, \"reset_index\"):\n",
    "                continue\n",
    "\n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders[\"symbol\"].values:\n",
    "                    continue\n",
    "\n",
    "                # Get transactions for this stock\n",
    "                stock_tx = df_insiders[df_insiders[\"symbol\"] == symbol].copy()\n",
    "\n",
    "                # Separate purchases and sales\n",
    "                # The text typically says \"Purchase\" or \"Sale\"\n",
    "                buys = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.contains(\"Purchase\", case=False, na=False)\n",
    "                ]\n",
    "                sells = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.contains(\"Sale\", case=False, na=False)\n",
    "                ]\n",
    "\n",
    "                # Calculate total buy/sell volume\n",
    "                buy_vol = buys[\"shares\"].sum() if not buys.empty else 0\n",
    "                sell_vol = sells[\"shares\"].sum() if not sells.empty else 0\n",
    "\n",
    "                # Get current price\n",
    "                current_price = None\n",
    "                try:\n",
    "                    if isinstance(price_data, dict) and symbol in price_data:\n",
    "                        current_price = price_data[symbol].get(\n",
    "                            \"regularMarketPrice\", None\n",
    "                        )\n",
    "                except:\n",
    "                    current_price = None\n",
    "\n",
    "                # Only keep if net buying is positive\n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append(\n",
    "                        {\n",
    "                            \"Ticker\": symbol,\n",
    "                            \"Current_Price\": current_price,\n",
    "                            \"Insider_Buys_Count\": len(buys),\n",
    "                            \"Net_Shares_Bought\": buy_vol - sell_vol,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "\n",
    "# Run the insider filter\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df[\"Ticker\"].tolist()\n",
    "\n",
    "else:\n",
    "    print(\"'fortress_df' and 'strong_df' not found.\")\n",
    "\n",
    "Fortress_insiders_1 = filter_for_insider_buying(target_tickers)\n",
    "print(f\"Created 'Fortress_insiders' with {len(Fortress_insiders_1)} rows.\")\n",
    "Fortress_insiders_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b0427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: 'strong_df' (107 tickers)\n",
      " Scanning 107 stocks for High-Conviction Insider Buying...\n",
      "\n",
      "Final Result: Found 12 Strong stocks with 2+ Insider Buys.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9a: INSIDER TRADING FILTER (STRONG LIST ONLY | MIN 2 BUYS)\n",
    "# =============================================================================\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "from yahooquery import Ticker\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def filter_for_strong_insider_buying(tickers):\n",
    "    \"\"\"\n",
    "    Find stocks where insiders are NET BUYERS with HIGH CONVICTION.\n",
    "    Criteria:\n",
    "    1. Net Buying (Buys > Sells)\n",
    "    2. Conviction (At least 2 separate Buy transactions)\n",
    "    \"\"\"\n",
    "    print(f\" Scanning {len(tickers)} stocks for High-Conviction Insider Buying...\")\n",
    "    insider_picks = []\n",
    "\n",
    "    # Conservative chunk size for stability\n",
    "    chunk_size = 15\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Delay to prevent API blocking\n",
    "            time.sleep(1.0)\n",
    "\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_insiders = yq.insider_transactions\n",
    "            price_data = yq.price\n",
    "\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, \"reset_index\"):\n",
    "                continue\n",
    "\n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders[\"symbol\"].values:\n",
    "                    continue\n",
    "\n",
    "                stock_tx = df_insiders[df_insiders[\"symbol\"] == symbol].copy()\n",
    "\n",
    "                # Robust lowercase search\n",
    "                buys = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.contains(\"purchase\", na=False)\n",
    "                ]\n",
    "                sells = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.contains(\"sale\", na=False)\n",
    "                ]\n",
    "\n",
    "                # === NEW FILTER: MINIMUM 2 BUY TRANSACTIONS ===\n",
    "                if len(buys) < 2:\n",
    "                    continue\n",
    "\n",
    "                buy_vol = buys[\"shares\"].sum() if not buys.empty else 0\n",
    "                sell_vol = sells[\"shares\"].sum() if not sells.empty else 0\n",
    "\n",
    "                # Logic: Net Positive Buying\n",
    "                if buy_vol > sell_vol:\n",
    "                    current_price = None\n",
    "                    try:\n",
    "                        if isinstance(price_data, dict) and symbol in price_data:\n",
    "                            current_price = price_data[symbol].get(\n",
    "                                \"regularMarketPrice\", None\n",
    "                            )\n",
    "                    except:\n",
    "                        current_price = 0\n",
    "\n",
    "                    insider_picks.append(\n",
    "                        {\n",
    "                            \"Ticker\": symbol,\n",
    "                            \"Current_Price\": current_price,\n",
    "                            \"Insider_Buys_Count\": len(buys),\n",
    "                            \"Net_Shares_Bought\": buy_vol - sell_vol,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION (STRONG_DF ONLY)\n",
    "# =========================================\n",
    "\n",
    "target_tickers = []\n",
    "\n",
    "# Check for 'strong_df' (or variations of the name)\n",
    "if \"strong_df\" in locals() and not strong_df.empty:\n",
    "    print(f\"Source: 'strong_df' ({len(strong_df)} tickers)\")\n",
    "    target_tickers = strong_df[\"Ticker\"].tolist()\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Error: 'strong_df' variable not found. Please run the Strong Filter cell first.\"\n",
    "    )\n",
    "\n",
    "# Run Scan\n",
    "if len(target_tickers) > 0:\n",
    "    # Remove duplicates and Sort\n",
    "    unique_tickers = sorted(list(set(target_tickers)))\n",
    "\n",
    "    Strong_insiders = filter_for_strong_insider_buying(unique_tickers)\n",
    "\n",
    "    print(\n",
    "        f\"\\nFinal Result: Found {len(Strong_insiders)} Strong stocks with 2+ Insider Buys.\"\n",
    "    )\n",
    "\n",
    "    if not Strong_insiders.empty:\n",
    "        # Sort by Conviction\n",
    "        Strong_insiders = Strong_insiders.sort_values(\n",
    "            by=\"Net_Shares_Bought\", ascending=False\n",
    "        )\n",
    "        Strong_insiders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e51c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0fe9401a-e722-480b-a15e-e97a1bb48ebd",
       "rows": [
        [
         "0",
         "MU",
         "362.75",
         "3",
         "167433.0"
        ],
        [
         "1",
         "CDE",
         "22.58",
         "21",
         "1650770.0"
        ],
        [
         "2",
         "HXL",
         "82.59",
         "6",
         "14327.0"
        ],
        [
         "3",
         "GIL",
         "63.22",
         "105",
         "1426104.0"
        ],
        [
         "4",
         "SHLS",
         "9.27",
         "3",
         "8335.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MU</td>\n",
       "      <td>362.75</td>\n",
       "      <td>3</td>\n",
       "      <td>167433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDE</td>\n",
       "      <td>22.58</td>\n",
       "      <td>21</td>\n",
       "      <td>1650770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HXL</td>\n",
       "      <td>82.59</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIL</td>\n",
       "      <td>63.22</td>\n",
       "      <td>105</td>\n",
       "      <td>1426104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>9.27</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0     MU         362.75                   3           167433.0\n",
       "1    CDE          22.58                  21          1650770.0\n",
       "2    HXL          82.59                   6            14327.0\n",
       "3    GIL          63.22                 105          1426104.0\n",
       "4   SHLS           9.27                   3             8335.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fortress_insiders = pd.concat([Fortress_insiders_1, Strong_insiders], ignore_index=True)\n",
    "Fortress_insiders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b15b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Analyst-Vetted Insider List\n",
      "\n",
      "--- RVOL CATALYST: Checking volume for 24 Insider picks ---\n",
      "\n",
      "SUCCESS: Catalyst candidates saved to 'YfinanceDataDump/Insider_RVOL_Catalysts_USA.csv'\n",
      "Original Insider Count: 24 -> Catalyst Count: 5\n",
      "\n",
      "--- INSIDER STOCKS WITH HIGH VOLUME SPIKES ---\n",
      "  Ticker  Current_Price  RVOL  Insider_Buys_Count  Net_Shares_Bought\n",
      "4   AXTA          33.57  1.97                   7             7366.0\n",
      "0     MU         362.75  1.66                   3           167433.0\n",
      "2   SHLS           9.27  1.64                   3             8335.0\n",
      "3   HSIC          79.98  1.59                   5            16257.0\n",
      "1    CDE          22.58  1.50                  21          1650770.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9b: RELATIVE VOLUME (RVOL) CATALYST SCAN\n",
    "# =============================================================================\n",
    "# This checks your \"Insider Picks\" for unusual institutional activity.\n",
    "# RVOL > 1.5 means volume is 150% of normal (institutions are active).\n",
    "# RVOL > 2.0 is a massive \"Ignition\" signal.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_rvol_catalyst(df_input, rvol_threshold=1.5):\n",
    "    \"\"\"\n",
    "    Calculates Relative Volume (RVOL).\n",
    "    RVOL = Current Volume / Average Volume (30-day).\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [RVOL Catalyst] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(f\"\\n--- RVOL CATALYST: Checking volume for {len(tickers)} Insider picks ---\")\n",
    "\n",
    "    # 1. Fetch History (Need ~2 months to get a clean 30-day average)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"3mo\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    catalyst_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need at least 30 days of volume data\n",
    "            if len(df_hist) < 30:\n",
    "                continue\n",
    "\n",
    "            # 2. Get Volumes\n",
    "            # Current Volume (Last completed bar)\n",
    "            current_vol = df_hist[\"Volume\"].iloc[-1]\n",
    "\n",
    "            # Average Volume (Previous 30 days, excluding today to avoid skewing the average)\n",
    "            avg_vol = df_hist[\"Volume\"].iloc[-31:-1].mean()\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if avg_vol == 0:\n",
    "                continue\n",
    "\n",
    "            # 3. Calculate RVOL\n",
    "            rvol = current_vol / avg_vol\n",
    "\n",
    "            # 4. Filter\n",
    "            if rvol > rvol_threshold:\n",
    "                # Get base data\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                base_row[\"RVOL\"] = round(rvol, 2)\n",
    "                base_row[\"Avg_Vol_30D\"] = int(avg_vol)\n",
    "                base_row[\"Current_Vol\"] = int(current_vol)\n",
    "\n",
    "                catalyst_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(catalyst_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# We check 'Fortress_insiders' first (Best List)\n",
    "# If that doesn't exist, we check the raw 'Fortress_insiders' list\n",
    "if \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    target_df = Fortress_insiders\n",
    "    print(\"Source: Analyst-Vetted Insider List\")\n",
    "elif \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    target_df = Fortress_insiders\n",
    "    print(\"Source: Raw Insider List\")\n",
    "else:\n",
    "    target_df = pd.DataFrame()\n",
    "\n",
    "if not target_df.empty:\n",
    "    # Run the scan\n",
    "    # Threshold 1.5 = 150% of normal volume\n",
    "    Insider_Catalyst_DF = apply_rvol_catalyst(target_df, rvol_threshold=1.5)\n",
    "\n",
    "    if not Insider_Catalyst_DF.empty:\n",
    "        # Sort by highest RVOL (Biggest Catalyst)\n",
    "        Insider_Catalyst_DF = Insider_Catalyst_DF.sort_values(\n",
    "            by=\"RVOL\", ascending=False\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        CATALYST_CSV = \"YfinanceDataDump/Insider_RVOL_Catalysts_USA.csv\"\n",
    "        Insider_Catalyst_DF.to_csv(CATALYST_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Catalyst candidates saved to '{CATALYST_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Insider Count: {len(target_df)} -> Catalyst Count: {len(Insider_Catalyst_DF)}\"\n",
    "        )\n",
    "\n",
    "        # --- FIX IS HERE: Changed 'Price' to 'Current_Price' ---\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Current_Price\",\n",
    "            \"RVOL\",\n",
    "            \"Insider_Buys_Count\",\n",
    "            \"Net_Shares_Bought\",\n",
    "        ]\n",
    "\n",
    "        # Only add Analyst_Verdict if it actually exists in the dataframe\n",
    "        if \"Analyst_Verdict\" in Insider_Catalyst_DF.columns:\n",
    "            cols.append(\"Analyst_Verdict\")\n",
    "\n",
    "        print(\"\\n--- INSIDER STOCKS WITH HIGH VOLUME SPIKES ---\")\n",
    "        print(Insider_Catalyst_DF[cols].head(15))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. No Insider picks are currently seeing high relative volume (>1.5x).\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Error: No Insider DataFrame found. Please run the Insider Scan cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scanning 220 stocks for Insider Buying...\n",
      "  Analyst Filter: 12 -> 10 stocks (Min Rating: Buy).\n",
      "\n",
      "  Final List: 10 stocks (Fortress + Insider Buying + Analyst Buy Rating)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 10. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "\n",
    "    tickers = df_insiders[\"Ticker\"].tolist()\n",
    "\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "\n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and \"recommendationMean\" in data:\n",
    "                    score = data.get(\"recommendationMean\")\n",
    "\n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append(\n",
    "                            {\n",
    "                                \"Ticker\": t,\n",
    "                                \"Analyst_Score\": score,\n",
    "                                \"Analyst_Verdict\": data.get(\"recommendationKey\", \"N/A\"),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "\n",
    "        if df_analyst.empty:\n",
    "            print(\" No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders  # Return original if no data found\n",
    "\n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on=\"Ticker\", how=\"inner\")\n",
    "\n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged[\"Analyst_Score\"] <= max_score].copy()\n",
    "\n",
    "        print(\n",
    "            f\"  Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\"\n",
    "        )\n",
    "        return final_df.sort_values(by=\"Analyst_Score\", ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df[\"Ticker\"].tolist()\n",
    "else:\n",
    "    # Backup list just in case need to update periodically\n",
    "    target_tickers = [\n",
    "        \"PET.TO\",\n",
    "        \"MFI.TO\",\n",
    "        \"TXG.TO\",\n",
    "        \"SAP.TO\",\n",
    "        \"PAAS.TO\",\n",
    "        \"NEO.TO\",\n",
    "        \"WPM.TO\",\n",
    "        \"FNV.TO\",\n",
    "        \"LUG.TO\",\n",
    "        \"DPM.TO\",\n",
    "        \"ASM.TO\",\n",
    "        \"PNG.V\",\n",
    "        \"DSG.TO\",\n",
    "        \"KNT.TO\",\n",
    "        \"GGD.TO\",\n",
    "        \"GRGD.TO\",\n",
    "        \"WDO.TO\",\n",
    "        \"OGC.TO\",\n",
    "        \"DNG.TO\",\n",
    "        \"CLS.TO\",\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with Data Wrangler\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(\n",
    "        insider_winners, max_score=2.5\n",
    "    )\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(\n",
    "        f\"\\n  Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\"\n",
    "    )\n",
    "    Fortress_insiders_Analyst_buy.head()\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d999738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing EV/EBITDA for 220 Fortress stocks...\n",
      "\n",
      "--- SECTOR AVERAGES (EV/EBITDA) ---\n",
      "                Sector  Sector_Avg_EV_EBITDA\n",
      "       Basic Materials                 15.97\n",
      "Communication Services                 19.16\n",
      "     Consumer Cyclical                 14.37\n",
      "    Consumer Defensive                 15.98\n",
      "                Energy                  9.27\n",
      "            Healthcare                 20.85\n",
      "           Industrials                 20.93\n",
      "            Technology                 22.16\n",
      "\n",
      "âœ… Found 129 Undervalued Stocks\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: BURRY EV/EBITDA FILTER For Fortress Stocks\n",
    "# =============================================================================\n",
    "# EV/EBITDA is a valuation metric popular with hedge fund manager Michael Burry.\n",
    "#\n",
    "# EV = Enterprise Value = Market Cap + Debt - Cash\n",
    "#      (What it would cost to buy the whole company)\n",
    "#\n",
    "# EBITDA = Earnings Before Interest, Taxes, Depreciation, and Amortization\n",
    "#          (Proxy for operating cash flow)\n",
    "#\n",
    "# EV/EBITDA tells you how many years of cash flow it would take to buy the company.\n",
    "# Lower is better (cheaper stock).\n",
    "# We compare each stock to its SECTOR AVERAGE to find relative value.\n",
    "\n",
    "\n",
    "def filter_burry_ev_ebitda(df_input):\n",
    "    \"\"\"\n",
    "    Find stocks trading at a discount to their sector average.\n",
    "\n",
    "    Logic: A stock with EV/EBITDA of 8x is \"cheap\" in a sector\n",
    "           where the average is 15x.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks cheaper than their sector average\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\" Input DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Analyzing EV/EBITDA for {len(df_input)} Fortress stocks...\")\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "\n",
    "    # Fetch data in bulk\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        data = yq.get_modules(\"defaultKeyStatistics financialData summaryDetail\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ev_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            ticker_data = data.get(ticker, {})\n",
    "            if isinstance(ticker_data, str):\n",
    "                continue\n",
    "\n",
    "            stats = ticker_data.get(\"defaultKeyStatistics\", {})\n",
    "            fin_data = ticker_data.get(\"financialData\", {})\n",
    "            summary = ticker_data.get(\"summaryDetail\", {})\n",
    "\n",
    "            # Try to get pre-calculated EV/EBITDA\n",
    "            ev_ebitda = stats.get(\"enterpriseToEbitda\")\n",
    "\n",
    "            # If not available, calculate manually\n",
    "            if ev_ebitda is None:\n",
    "                try:\n",
    "                    market_cap = summary.get(\"marketCap\")\n",
    "                    total_debt = fin_data.get(\"totalDebt\")\n",
    "                    total_cash = fin_data.get(\"totalCash\")\n",
    "                    ebitda = fin_data.get(\"ebitda\")\n",
    "\n",
    "                    if all(\n",
    "                        v is not None\n",
    "                        for v in [market_cap, total_debt, total_cash, ebitda]\n",
    "                    ):\n",
    "                        if ebitda != 0:\n",
    "                            # EV = Market Cap + Debt - Cash\n",
    "                            enterprise_value = market_cap + total_debt - total_cash\n",
    "                            ev_ebitda = enterprise_value / ebitda\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Only include positive values (profitable companies)\n",
    "            if ev_ebitda is not None and ev_ebitda > 0:\n",
    "                ev_data.append({\"Ticker\": ticker, \"EV/EBITDA\": round(ev_ebitda, 2)})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    df_vals = pd.DataFrame(ev_data)\n",
    "\n",
    "    if df_vals.empty:\n",
    "        print(\"Could not retrieve EV/EBITDA data.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Merge with sector data\n",
    "    merged_df = pd.merge(df_input, df_vals, on=\"Ticker\", how=\"inner\")\n",
    "\n",
    "    # Calculate sector averages\n",
    "    print(\"\\n--- SECTOR AVERAGES (EV/EBITDA) ---\")\n",
    "    sector_stats = merged_df.groupby(\"Sector\")[\"EV/EBITDA\"].mean().reset_index()\n",
    "    sector_stats.rename(columns={\"EV/EBITDA\": \"Sector_Avg_EV_EBITDA\"}, inplace=True)\n",
    "    sector_stats[\"Sector_Avg_EV_EBITDA\"] = sector_stats[\"Sector_Avg_EV_EBITDA\"].round(2)\n",
    "\n",
    "    print(sector_stats.to_string(index=False))\n",
    "\n",
    "    # Merge with sector averages\n",
    "    final_df = pd.merge(merged_df, sector_stats, on=\"Sector\", how=\"left\")\n",
    "\n",
    "    # Filter: Keep only stocks CHEAPER than sector average\n",
    "    burry_picks = final_df[\n",
    "        final_df[\"EV/EBITDA\"] < final_df[\"Sector_Avg_EV_EBITDA\"]\n",
    "    ].copy()\n",
    "\n",
    "    # Calculate discount percentage\n",
    "    # Discount = 1 - (Stock EV/EBITDA / Sector Average)\n",
    "    burry_picks[\"Discount_%\"] = round(\n",
    "        (1 - (burry_picks[\"EV/EBITDA\"] / burry_picks[\"Sector_Avg_EV_EBITDA\"])) * 100, 2\n",
    "    )\n",
    "\n",
    "    # Sort by biggest discount\n",
    "    burry_picks = burry_picks.sort_values(by=\"Discount_%\", ascending=False)\n",
    "\n",
    "    return burry_picks\n",
    "\n",
    "\n",
    "# Run the Burry filter\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "    if not Fortress_Burry_EV_EBITDA.empty:\n",
    "        print(f\"\\nâœ… Found {len(Fortress_Burry_EV_EBITDA)} Undervalued Stocks\")\n",
    "        Fortress_Burry_EV_EBITDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BURRY TECHNICALS: Analyzing 129 candidates ---\n",
      "\n",
      "SUCCESS: Technical picks saved to 'YfinanceDataDump/Burry_Technical_Picks_USA.csv'\n",
      "Original Undervalued Count: 129\n",
      "Survivors (Uptrend Only): 96\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11a: BURRY TECHNICAL SCAN (TREND + SQUEEZE)\n",
    "# =============================================================================\n",
    "# This combines two strategies into one efficient pass:\n",
    "# 1. SAFETY: Filters out downtrends (Price < 200 SMA).\n",
    "# 2. OPPORTUNITY: Calculates \"Volatility Squeeze\" to find coiling stocks.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_burry_technicals(df_input):\n",
    "    \"\"\"\n",
    "    Fetches 1y history ONCE.\n",
    "    Applies Trend Filter (Price > SMA200).\n",
    "    Calculates Squeeze Metrics (Bandwidth).\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Burry Technicals] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(f\"\\n--- BURRY TECHNICALS: Analyzing {len(tickers)} candidates ---\")\n",
    "\n",
    "    # 1. Fetch History (1 Year is enough for both SMA200 and Squeeze)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need sufficient data\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history (<200 days).\")\n",
    "                continue\n",
    "\n",
    "            # --- METRIC 1: TREND (SMA 200) ---\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # HARD FILTER: Must be in Uptrend\n",
    "            if current_price < sma_200:\n",
    "                continue\n",
    "\n",
    "            dist_sma_pct = ((current_price - sma_200) / sma_200) * 100\n",
    "\n",
    "            # --- METRIC 2: SQUEEZE (Bollinger Bands) ---\n",
    "            sma_20 = df_hist[\"Close\"].rolling(window=20).mean()\n",
    "            std_20 = df_hist[\"Close\"].rolling(window=20).std()\n",
    "\n",
    "            upper = sma_20 + (2 * std_20)\n",
    "            lower = sma_20 - (2 * std_20)\n",
    "            bandwidth = (upper - lower) / sma_20\n",
    "\n",
    "            # Check Squeeze Status (Lowest 15% of last 6 months)\n",
    "            recent_bw = bandwidth.tail(126)  # ~6 months\n",
    "            current_bw = recent_bw.iloc[-1]\n",
    "            squeeze_threshold = recent_bw.quantile(0.15)\n",
    "            is_squeezing = current_bw <= squeeze_threshold\n",
    "\n",
    "            # --- COMPILE RESULT ---\n",
    "            # Get base fundamental data\n",
    "            base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "            # Add Technical Data\n",
    "            base_row[\"Price\"] = round(current_price, 2)\n",
    "            base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "            base_row[\"Trend_Dist_%\"] = round(dist_sma_pct, 2)\n",
    "            base_row[\"Bandwidth_%\"] = round(current_bw * 100, 2)\n",
    "            base_row[\"In_Squeeze\"] = \"YES\" if is_squeezing else \"No\"\n",
    "\n",
    "            results_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "if \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "\n",
    "    # Run the consolidated scan\n",
    "    Burry_Technicals_DF = apply_burry_technicals(Fortress_Burry_EV_EBITDA)\n",
    "\n",
    "    if not Burry_Technicals_DF.empty:\n",
    "        # Sort by \"Squeeziness\" (Bandwidth), but favor those in Squeeze first\n",
    "        # We sort by In_Squeeze (descending, so YES comes first) then Bandwidth (ascending)\n",
    "        Burry_Technicals_DF = Burry_Technicals_DF.sort_values(\n",
    "            by=[\"In_Squeeze\", \"Bandwidth_%\"], ascending=[False, True]\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        TECH_CSV = \"YfinanceDataDump/Burry_Technical_Picks_USA.csv\"\n",
    "        Burry_Technicals_DF.to_csv(TECH_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Technical picks saved to '{TECH_CSV}'\")\n",
    "        print(f\"Original Undervalued Count: {len(Fortress_Burry_EV_EBITDA)}\")\n",
    "        print(f\"Survivors (Uptrend Only): {len(Burry_Technicals_DF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa7b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing EV/EBITDA for 220 Fortress stocks...\n",
      "\n",
      "--- SECTOR AVERAGES (EV/EBITDA) ---\n",
      "                Sector  Sector_Avg_EV_EBITDA\n",
      "       Basic Materials                 15.97\n",
      "Communication Services                 19.16\n",
      "     Consumer Cyclical                 14.37\n",
      "    Consumer Defensive                 15.98\n",
      "                Energy                  9.27\n",
      "            Healthcare                 20.85\n",
      "           Industrials                 20.93\n",
      "            Technology                 22.16\n",
      "âœ… Analyst Filter: 125 -> 104 stocks (Min Rating: Buy).\n",
      "\n",
      "ðŸš€ Final List: 104 stocks (Fortress + Burry + Analyst Buy Rating)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 12. ANALYST FILTER FUNCTION FOR Burry EV/EBITDA PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if Fortress_Burry_EV_EBITDA.empty:\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "    tickers = Fortress_Burry_EV_EBITDA[\"Ticker\"].tolist()\n",
    "\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "\n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and \"recommendationMean\" in data:\n",
    "                    score = data.get(\"recommendationMean\")\n",
    "\n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append(\n",
    "                            {\n",
    "                                \"Ticker\": t,\n",
    "                                \"Analyst_Score\": score,\n",
    "                                \"Analyst_Verdict\": data.get(\"recommendationKey\", \"N/A\"),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "\n",
    "        if df_analyst.empty:\n",
    "            print(\"âš ï¸ No Analyst ratings found for these tickers.\")\n",
    "            return Fortress_Burry_EV_EBITDA  # Return original if no data found\n",
    "\n",
    "        # Merge with the Fortress DataFrame\n",
    "        merged = pd.merge(\n",
    "            Fortress_Burry_EV_EBITDA, df_analyst, on=\"Ticker\", how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged[\"Analyst_Score\"] <= max_score].copy()\n",
    "\n",
    "        print(\n",
    "            f\"âœ… Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\"\n",
    "        )\n",
    "        return final_df.sort_values(by=\"Analyst_Score\", ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in Analyst Filter: {e}\")\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    target_tickers = Fortress_Burry_EV_EBITDA[\"Ticker\"].tolist()\n",
    "\n",
    "\n",
    "# B. Run Insider Filter\n",
    "Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with Data Wrangler\n",
    "if not Fortress_Burry_EV_EBITDA.empty:\n",
    "    Fortress_Burry_Analyst_buy = filter_for_analyst_ratings(\n",
    "        Fortress_Burry_EV_EBITDA, max_score=2.5\n",
    "    )\n",
    "else:\n",
    "    Fortress_Burry_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_Burry_Analyst_buy.empty:\n",
    "    print(\n",
    "        f\"\\nðŸš€ Final List: {len(Fortress_Burry_Analyst_buy)} stocks (Fortress + Burry + Analyst Buy Rating)\"\n",
    "    )\n",
    "    Fortress_Burry_Analyst_buy.head()\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc57c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEEP VALUE GEMS FOUND: 2\n",
      "============================================================\n",
      "Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 13. THE \"DEEP VALUE\" INTERSECTION (Buffett + Burry)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Ensure we have the Buffett Data\n",
    "if \"Buffett_Value_DF\" not in locals():\n",
    "    print(\"Buffett Data not found. Running scan now...\")\n",
    "    if \"get_buffett_value_picks\" in globals() and \"final_results\" in locals():\n",
    "        Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    else:\n",
    "        print(\"Missing 'final_results' or 'get_buffett_value_picks' function.\")\n",
    "        Buffett_Value_DF = pd.DataFrame()\n",
    "\n",
    "# 2. Ensure we have the Burry Data\n",
    "if \"Fortress_Burry_EV_EBITDA\" not in locals():\n",
    "    print(\"Please run the Burry EV/EBITDA filter cell first.\")\n",
    "    Fortress_Burry_EV_EBITDA = pd.DataFrame()\n",
    "\n",
    "# 3. THE MERGE (Finding the Overlap)\n",
    "if not Buffett_Value_DF.empty and not Fortress_Burry_EV_EBITDA.empty:\n",
    "\n",
    "    # Merge on Ticker to find stocks that appear in BOTH lists\n",
    "    # We use an 'inner' join, which means \"keep only if in both\"\n",
    "    Deep_Value_Intersection = pd.merge(\n",
    "        Buffett_Value_DF[[\"Ticker\", \"P/B Ratio\", \"ROE %\", \"Debt/Eq %\"]],\n",
    "        Fortress_Burry_EV_EBITDA[\n",
    "            [\n",
    "                \"Ticker\",\n",
    "                \"Price\",\n",
    "                \"Sector\",\n",
    "                \"EV/EBITDA\",\n",
    "                \"Sector_Avg_EV_EBITDA\",\n",
    "                \"Discount_%\",\n",
    "                \"Tier\",\n",
    "            ]\n",
    "        ],\n",
    "        on=\"Ticker\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    if not Deep_Value_Intersection.empty:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"DEEP VALUE GEMS FOUND: {len(Deep_Value_Intersection)}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\n",
    "            \"Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\"\n",
    "        )\n",
    "\n",
    "        # Sort by the \"Discount\" (how cheap they are vs sector)\n",
    "        Deep_Value_Intersection = Deep_Value_Intersection.sort_values(\n",
    "            by=\"Discount_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Tier\",\n",
    "            \"P/B Ratio\",\n",
    "            \"EV/EBITDA\",\n",
    "            \"Sector_Avg_EV_EBITDA\",\n",
    "            \"Discount_%\",\n",
    "            \"Sector\",\n",
    "        ]\n",
    "        Deep_Value_Intersection[cols].head()\n",
    "\n",
    "    else:\n",
    "        print(\"\\n No stocks passed BOTH filters.\")\n",
    "        print(\n",
    "            \"This means no stock is both 'Below Book Value' AND 'Cheaper than Sector Average' at the same time.\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Buffett Count: {len(Buffett_Value_DF)} | Burry Count: {len(Fortress_Burry_EV_EBITDA)}\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"Cannot combine. One of the filters returned 0 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dcc4d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Analyst-Vetted Insider List.\n",
      "Using Analyst-Vetted Burry List.\n",
      "\n",
      "============================================================\n",
      "ðŸš€ HIGH CONVICTION WINNERS FOUND: 8\n",
      "============================================================\n",
      "Criteria: Cheap vs Sector (Burry) + Insider Buying\n",
      "\n",
      "Saved to: YfinanceDataDump\\High_Conviction_Picks_USA.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: THE \"HIGH CONVICTION\" INTERSECTION (BURRY + INSIDERS)\n",
    "# =============================================================================\n",
    "# This finds stocks that are BOTH:\n",
    "# 1. Undervalued vs their Sector (Burry EV/EBITDA)\n",
    "# 2. Being accumulated by Insiders (Insider Confidence)\n",
    "#\n",
    "# This is a powerful \"Anti-Value Trap\" filter. Insiders rarely buy\n",
    "# sinking ships, even if they look cheap on paper.\n",
    "\n",
    "# --- 1. DETECT BEST AVAILABLE DATAFRAMES ---\n",
    "\n",
    "# Try to find the Insider list (preferring the one with Analyst ratings if available)\n",
    "if (\n",
    "    \"Fortress_insiders_Analyst_buy\" in locals()\n",
    "    and not Fortress_insiders_Analyst_buy.empty\n",
    "):\n",
    "    df_insider_source = Fortress_insiders_Analyst_buy\n",
    "    print(\"Using Analyst-Vetted Insider List.\")\n",
    "elif \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    df_insider_source = Fortress_insiders\n",
    "    print(\"Using Raw Insider List (No Analyst Check).\")\n",
    "else:\n",
    "    df_insider_source = pd.DataFrame()\n",
    "    print(\"Warning: No Insider data found.\")\n",
    "\n",
    "# Try to find the Burry list (preferring the one with Analyst ratings if available)\n",
    "if \"Fortress_Burry_Analyst_buy\" in locals() and not Fortress_Burry_Analyst_buy.empty:\n",
    "    df_burry_source = Fortress_Burry_Analyst_buy\n",
    "    print(\"Using Analyst-Vetted Burry List.\")\n",
    "elif \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    df_burry_source = Fortress_Burry_EV_EBITDA\n",
    "    print(\"Using Raw Burry List (No Analyst Check).\")\n",
    "else:\n",
    "    df_burry_source = pd.DataFrame()\n",
    "    print(\"Warning: No Burry EV/EBITDA data found.\")\n",
    "\n",
    "# --- 2. PERFORM THE INTERSECTION ---\n",
    "\n",
    "if not df_insider_source.empty and not df_burry_source.empty:\n",
    "\n",
    "    # We merge on 'Ticker'. 'inner' means keep only stocks found in BOTH lists.\n",
    "    # We use suffixes=('', '_drop') to handle duplicate columns (like Price)\n",
    "    high_conviction_df = pd.merge(\n",
    "        df_burry_source[\n",
    "            [\n",
    "                \"Ticker\",\n",
    "                \"Price\",\n",
    "                \"Sector\",\n",
    "                \"Tier\",\n",
    "                \"EV/EBITDA\",\n",
    "                \"Sector_Avg_EV_EBITDA\",\n",
    "                \"Discount_%\",\n",
    "            ]\n",
    "        ],\n",
    "        df_insider_source[[\"Ticker\", \"Insider_Buys_Count\", \"Net_Shares_Bought\"]],\n",
    "        on=\"Ticker\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    if not high_conviction_df.empty:\n",
    "        # Sort by Discount % (Deepest value first)\n",
    "        high_conviction_df = high_conviction_df.sort_values(\n",
    "            by=\"Discount_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"ðŸš€ HIGH CONVICTION WINNERS FOUND: {len(high_conviction_df)}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Criteria: Cheap vs Sector (Burry) + Insider Buying\")\n",
    "\n",
    "        # Reorder columns for readability\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Sector\",\n",
    "            \"Tier\",\n",
    "            \"Discount_%\",\n",
    "            \"EV/EBITDA\",\n",
    "            \"Insider_Buys_Count\",\n",
    "            \"Net_Shares_Bought\",\n",
    "        ]\n",
    "\n",
    "        # Display nicely\n",
    "        high_conviction_df[cols].head()\n",
    "\n",
    "        # Optional: Save to CSV\n",
    "        save_path = os.path.join(DATA_FOLDER, \"High_Conviction_Picks_USA.csv\")\n",
    "        high_conviction_df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nSaved to: {save_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nNo overlap found. No stock is both 'Cheap vs Sector' AND 'Insider Buy' target.\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Burry Count: {len(df_burry_source)} | Insider Count: {len(df_insider_source)}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\nCannot run intersection. Missing one or both source lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 12 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n",
      "\n",
      "--- Final Watchlist ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = [\n",
    "    \"SHLS\",\n",
    "    \"BANC\",\n",
    "    \"ONB\",\n",
    "    \"UBER\",\n",
    "    \"ADMA\",\n",
    "    \"MIR\",\n",
    "    \"APG\",\n",
    "    \"SEI\",\n",
    "    \"FLEX\",\n",
    "    \"DD\",\n",
    "    \"SVM\",\n",
    "    \"GIL\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "\n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "\n",
    "            finviz_data.append(\n",
    "                {\n",
    "                    \"Ticker\": ticker,\n",
    "                    \"Recom\": info.get(\"Recom\", np.nan),\n",
    "                    \"Target_Price\": info.get(\"Target Price\", np.nan),\n",
    "                }\n",
    "            )\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append(\n",
    "                {\"Ticker\": ticker, \"Recom\": np.nan, \"Target_Price\": np.nan}\n",
    "            )\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "\n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "\n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(\n",
    "            ticker_list,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            group_by=\"ticker\",\n",
    "            progress=False,\n",
    "            threads=True,\n",
    "        )\n",
    "        yf_stats = []\n",
    "\n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=[\"Close\"])\n",
    "                if len(df) < 20:\n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df[\"Close\"].iloc[-1]\n",
    "                prev_close = df[\"Close\"].iloc[-2]\n",
    "\n",
    "                high_52 = df[\"High\"].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "\n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "\n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df[\"Close\"].pct_change().std() * 100\n",
    "\n",
    "                # Relative Volume\n",
    "                curr_vol = df[\"Volume\"].iloc[-1]\n",
    "                avg_vol = df[\"Volume\"].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df[\"Close\"].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100\n",
    "\n",
    "                yf_stats.append(\n",
    "                    {\n",
    "                        \"Ticker\": ticker,\n",
    "                        \"Price\": round(current_price, 2),\n",
    "                        \"Change_%\": round(change_pct, 2),\n",
    "                        \"52W_MA\": round(ma_52w, 2),  # <--- Added Here\n",
    "                        \"Drop_from_High_%\": round(drop_from_high, 2),\n",
    "                        \"Volatility_%\": round(volatility, 2),\n",
    "                        \"Rel_Volume\": round(rel_vol, 2),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "\n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on=\"Ticker\", how=\"outer\")\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "\n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Change_%\",\n",
    "            \"52W_MA\",\n",
    "            \"Drop_from_High_%\",\n",
    "            \"Recom\",\n",
    "            \"Target_Price\",\n",
    "            \"Rel_Volume\",\n",
    "            \"Volatility_%\",\n",
    "        ]\n",
    "\n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if \"Drop_from_High_%\" in watchlist_df.columns:\n",
    "        watchlist_df[\"Drop_from_High_%\"] = pd.to_numeric(\n",
    "            watchlist_df[\"Drop_from_High_%\"], errors=\"coerce\"\n",
    "        )\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        watchlist_df.sort_values(by=\"Drop_from_High_%\", ascending=True).head()\n",
    "    else:\n",
    "        watchlist_df.head()\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "333020a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded securely.\n",
      "\n",
      "Gemini 3 is thinking (High Reasoning Mode)... analyzing $['GIL']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Gemini 3 Sentiment Report: ['GIL'] (Gildan Activewear Inc.)\n",
       "**Reasoning Depth:** High  \n",
       "**Sentiment Score:** 8.5/10  \n",
       "**Verdict:** Buy / Speculative (Post-Merger Re-rating Play)\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis (Why it goes up)\n",
       "*   **HanesBrands Synergy Realization:** The massive acquisition of HanesBrands (completed Dec 1, 2025) is the primary catalyst. Management is targeting **$200 million in annual run-rate cost synergies**, which is expected to drive a low-20% EPS CAGR over the next three years.\n",
       "*   **Index Re-weighting Inflows:** As a result of the Hanes acquisition and new share issuance, Gildanâ€™s market cap has expanded, leading to increased weightings in the S&P/TSX Composite and potentially other indices. This forces passive fund inflows and attracts \"benchmark-hugging\" active managers.\n",
       "*   **Vertically Integrated Cost Advantage:** Gildanâ€™s low-cost manufacturing model in Central America and the Caribbean allows it to undercut competitors who source from ASEAN countries, particularly as trade tensions and tariffs (a growing macro concern) impact competitors more severely.\n",
       "*   **Strong Earnings Momentum:** The company has a consistent track record of beating EPS estimates (most recently Q3 2025). Analysts have been aggressively raising price targets, with some (UBS) projecting an upside to $110.\n",
       "\n",
       "### 2. The Bear Thesis (Why it goes down)\n",
       "*   **Integration Risk:** Doubling the companyâ€™s scale via HanesBrands is a \"transformative\" but risky move. Any hiccups in merging supply chains or manufacturing networks could delay the promised $200M in synergies.\n",
       "*   **Macro/Tariff Volatility:** While Gildan is vertically integrated, the broader apparel sector is highly sensitive to geopolitical trade wars. Recent headlines regarding US-EU retaliatory tariffs create a \"risk-off\" environment for consumer cyclicals.\n",
       "*   **Institutional \"Puppet Show\":** With institutional ownership as high as 86%, retail sentiment on forums (Reddit/AInvest) is skeptical. Traders fear \"institutional dumping\" or that the stock is a \"rigged roulette wheel\" where retail is the last to know if the merger integration fails.\n",
       "*   **High Debt Load:** To finance the $2.2B equity value of Hanes, Gildan has taken on significant leverage. A sustained high-interest-rate environment or a drop in consumer demand could pressure the balance sheet.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "*   **News Analysis**: The news cycle is currently **euphoric** regarding the \"Global Apparel Leader\" narrative following the HanesBrands deal. Headlines are dominated by the successful closing of the merger (Dec 2025) and analyst upgrades. There is little \"fear-mongering\" outside of general macro-economic trade tension reports, which are not specific to Gildan's core operations but impact its sector.\n",
       "*   **Smart Money**: Institutional flows are overwhelmingly positive. Major holders like **Janus Henderson Group** and **Cooke & Bieler** have maintained or slightly adjusted their massive stakes. Notably, the stockâ€™s inclusion in indices is creating a \"floor\" for the price as passive demand offsets occasional large-block sales from hedge funds who exited post-merger announcement. Insider activity has been quiet in the last 90 days, suggesting a \"wait-and-see\" approach during the integration phase.\n",
       "*   **Financial Statement Analysis**:\n",
       "    *   **Historic (Last 3 Years)**: Revenue has been steady but slow-growing ($3.2B average). Net margins have improved to a healthy **14.1%**, while ROE is exceptionally high at **31-35%** (though partially debt-fueled).\n",
       "    *   **Expected Performance**: For FY 2025, the company guided an EPS of **$3.45 - $3.51**. Post-merger, the consensus for Q4 2025 (reporting Feb 18/25, 2026) is an EPS of **$1.30**, a significant jump from the $0.83 - $1.15 range seen in previous years. The market is pricing in the \"Hanes effect\" early.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Conclusion\n",
       "**Verdict: Opportunity.**\n",
       "Gildan is currently in a \"Sweet Spot\" of market psychology. The price action (near 52-week highs around $63-$64) suggests the market has accepted the merger as a success, but the full value of the $200M cost synergies is not yet reflected in the stock price. \n",
       "\n",
       "**The \"Whisper\" Number**: While official consensus is $0.98â€“$1.30 for the upcoming quarter, the whisper on trading forums is a **beat toward $1.35**, driven by aggressive cost-cutting already underway in the Hanes supply chain.\n",
       "\n",
       "The current price is not a trap; it is a **re-rating in progress**. However, investors should monitor the Feb 2026 earnings call for any \"synergy slippage\" or warnings about the high debt-to-equity ratio (currently ~0.94 - 1.2x). If the management confirms a \"seamless integration,\" the path to the $75-$80 median analyst target is clear."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers_gemini = [\"GIL\"]\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# SECURE CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define the path to your key file\n",
    "# If the file is in the same folder as this notebook, just use the filename.\n",
    "KEY_FILE_PATH = (\n",
    "    r\"C:\\Users\\jdcc3\\OneDrive - McMaster University\\Gemini API Key\\gemini_key.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Reads the API key from a local file to avoid hardcoding it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            # .strip() removes any accidental newlines or spaces\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the file '{filepath}'\")\n",
    "        print(\"Please create a text file with your API key in it.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 2. Load the key and set the environment variable\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"CRITICAL: API Key not loaded. The script will fail.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# SENTIMENT ANALYSIS FUNCTION USING GROUNDING SEARCH GEMINI 3\n",
    "# ==========================================\n",
    "def analyze_sentiment_gemini_3(tickers_gemini, company_name=None):\n",
    "\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\nGemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\"\n",
    "    )\n",
    "\n",
    "    # Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        response_modalities=[\"TEXT\"],\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini} ({company_name if company_name else 'the company'}).\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology. Look for contradictions between price action and news.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric? (Look for scandals, lawsuits, or product breakthroughs).\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN in the last week?\n",
    "    3. **Institutional Flows**: Any reports of hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums vs. official guidance?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## Gemini 3 Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis (Why it goes up)\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis (Why it goes down)\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance over last 3 years + expected performance)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    [Summary of whether the current price is a trap or an opportunity]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-3-flash-preview\",  # Or 'gemini-3-flash-preview'\n",
    "            contents=prompt,\n",
    "            config=config,\n",
    "        )\n",
    "        display(Markdown(response.text))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "# Only run this if the key loaded successfully\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_sentiment_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc2bed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded securely.\n",
      "\n",
      "Gemini 3 is thinking (High Reasoning Mode)... analyzing $['SHLS']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Gemini Sentiment Report: ['SHLS']\n",
       "\n",
       "**Reasoning Depth:** High\n",
       "**Sentiment Score:** 7/10 (Cautiously Bullish)\n",
       "**Verdict:** **Speculative Buy**\n",
       "\n",
       "---\n",
       "\n",
       "### 1. The Bull Thesis\n",
       "*   **Backlog & Growth Inflection:** The strongest bull argument is the \"record backlog\" of **$720.9 million** reported in Q3, up 21% year-over-year. This provides high revenue visibility into 2026, countering fears of a slowdown.\n",
       "*   **Misinterpreted Insider Activity:** The market has partly priced in \"insider selling\" fears. However, a deep dive confirms the CFOâ€™s recent December sale was a **mandatory tax withholding** transaction, not a lack of confidence. This creates a dislocation between sentiment and reality.\n",
       "*   **Analyst Upside:** Despite a consensus \"Hold\" rating, major firms have recently lifted price targets (e.g., Goldman Sachs to $11, UBS to $12). The stock trading near ~$9.30 offers an attractive entry point relative to these targets, implying ~20-30% potential upside.\n",
       "*   **Rate Cut Beneficiary:** As a capital-intensive renewable energy play, SHLS is highly sensitive to interest rates. The narrative of \"rate cuts in 2026\" acts as a powerful sector-wide tailwind, potentially lowering project financing costs for Shoals' customers.\n",
       "\n",
       "### 2. The Bear Thesis\n",
       "*   **Legal Stalemate:** The patent war with Voltage is not the \"slam dunk\" bulls hoped for. The ITC recently terminated the investigation into the '153 patent finding no violation by Voltage's specific design. While Shoals has filed new complaints with newer patents, the lack of a decisive \"knockout\" blow means competition remains a threat to their moat.\n",
       "*   **Execution Risk:** The company is ramping up a new facility and expanding internationally. Any hiccups in manufacturing efficiency or margin compression during this ramp could punish the stock, which still trades at a premium valuation (P/E ~46x) relative to the broader industrial sector.\n",
       "*   **Short Interest Friction:** With short interest hovering around **8-10%**, there is a persistent group of sophisticated investors betting against the company. While not high enough to guarantee a \"squeeze,\" it indicates skepticism about the quality of their earnings or competitive position.\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "*   **News Analysis**:\n",
       "    *   **Virality:** News sentiment is \"Recovering.\" The narrative has shifted from \"rough year\" fears to \"turnaround\" hopes following the Q3 earnings beat. The patent news is complexâ€”headlines about \"losing\" the ITC case are initially negative, but the filing of *new* complaints keeps the fight alive, neutralizing the long-term impact.\n",
       "    *   **Key Event:** The Q3 revenue jump (+32.9% YoY) effectively silenced the \"growth is dead\" narrative, replacing it with an \"execution\" story.\n",
       "\n",
       "*   **Smart Money (Institutional Flows)**:\n",
       "    *   **Reality Check:** Retail rumors of \">100% institutional ownership\" are false. Actual data shows a crowded but rational trade.\n",
       "    *   **Activity:** Recent 13G filings (e.g., BlackRock, Vanguard) show steady holds rather than aggressive accumulation. The lack of massive *new* activist buying suggests institutions are waiting for the next earnings print (Feb 24, 2026) to confirm the turnaround is durable.\n",
       "    *   **Insider Truth:** CFO Dominic Bardos's sale in December was **coded \"F\" or similar for tax withholding** in filings, a non-discretionary move. This is a classic \"false bear signal\" that retail traders often misinterpret.\n",
       "\n",
       "*   **The \"Whisper\" Number**:\n",
       "    *   **Forum Sentiment:** Retail traders on Reddit and StockTwits are confused but hopeful. The \"Whisper\" price target is **$10.50 - $12.00**, viewing the stock as a \"catch-up trade\" that has lagged other solar peers.\n",
       "    *   **Rumor Control:** There is a persistent rumor of a \"short squeeze\" due to \"fake shares,\" but with days-to-cover at ~4.6 and short interest <11%, a massive squeeze is statistically unlikely without a major unexpected catalyst.\n",
       "\n",
       "*   **Financial Statement Analysis (Last 3y + Outlook)**:\n",
       "    *   **Trend:** Revenue has grown impressively from ~$175M (2020) to a TTM run rate approaching $500M. Net income has flipped from losses/breakeven to solid profitability ($11.9M in Q3).\n",
       "    *   **Outlook:** The company guided Q4 revenue to **$140M - $150M**, signaling accelerating momentum into 2026. The key metric to watch is **Gross Margin**, which recovered to 37% in Q3. Sustaining this level is critical for the bull case.\n",
       "\n",
       "### 4. Conclusion\n",
       "Shoals Technologies Group (SHLS) is currently a **dislocated asset**. The market is pricing it with \"patent loss\" and \"insider selling\" anxiety, while the fundamental reality shows record backlogs, misunderstood tax-related insider trades, and a continuing legal strategy.\n",
       "\n",
       "The sentiment score of **7/10** reflects this gap. The stock is not without riskâ€”primarily valuation and competitive pressureâ€”but the risk/reward ratio at ~$9 is favorable. The \"Verdict\" is a **Speculative Buy**, betting that the Feb 24th earnings will confirm the backlog conversion and force the stock to re-rate toward the $11-$12 analyst consensus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " INTERACTIVE SESSION: Ask follow-ups about ['SHLS']\n",
      " Type 'exit' or 'quit' to stop.\n",
      "==================================================\n",
      "\n",
      "Ending session.\n"
     ]
    }
   ],
   "source": [
    "tickers_gemini = [\"SHLS\"]\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# Senior Analyst with INTERACTIVE FOLLOW-UPS\n",
    "# ==========================================\n",
    "\n",
    "KEY_FILE_PATH = (\n",
    "    r\"C:\\Users\\jdcc3\\OneDrive - McMaster University\\Gemini API Key\\gemini_key.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"CRITICAL: API Key not loaded.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# INTERACTIVE ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_and_chat_gemini_3(tickers_gemini, company_name=None):\n",
    "\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\nGemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\"\n",
    "    )\n",
    "\n",
    "    # 1. Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    # 2. Configure the Chat with Tools (Search) and Reasoning\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        response_modalities=[\"TEXT\"],\n",
    "    )\n",
    "\n",
    "    # 3. Create the Chat Session (This holds the history)\n",
    "    chat = client.chats.create(\n",
    "        model=\"gemini-3-pro-preview\", config=config  # Recommended for reasoning + speed\n",
    "    )\n",
    "\n",
    "    # 4. Define the Initial Prompt\n",
    "    initial_prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini}.\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric?\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN?\n",
    "    3. **Institutional Flows**: Hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## Gemini Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance last 3y + outlook)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 5. Send Initial Request\n",
    "        response = chat.send_message(initial_prompt)\n",
    "        display(Markdown(response.text))\n",
    "\n",
    "        # ==========================================\n",
    "        # NEW: INTERACTIVE LOOP\n",
    "        # ==========================================\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\" INTERACTIVE SESSION: Ask follow-ups about {tickers_gemini}\")\n",
    "        print(\" Type 'exit' or 'quit' to stop.\")\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_question = input(\"\\nYour Question: \")\n",
    "\n",
    "            # Check for exit condition\n",
    "            if user_question.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "                print(\"Ending session.\")\n",
    "                break\n",
    "\n",
    "            # Send follow-up to the SAME chat session\n",
    "            print(\"Analyzing...\")\n",
    "            follow_up_response = chat.send_message(user_question)\n",
    "            display(Markdown(follow_up_response.text))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_and_chat_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
