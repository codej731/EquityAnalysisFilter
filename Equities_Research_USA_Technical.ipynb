{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ec8184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Windows async policy set\n",
      "âœ… yahooquery loaded\n",
      "âœ… yfinance loaded\n",
      "\n",
      "ðŸŽ‰ All imports complete!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: WINDOWS/VPN FIXES\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress noisy warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === WINDOWS ASYNC FIX ===\n",
    "if sys.platform == \"win32\":\n",
    "    import asyncio\n",
    "\n",
    "    try:\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "        print(\"Windows async policy set\")\n",
    "    except Exception as e:\n",
    "        print(f\"Async policy warning: {e}\")\n",
    "\n",
    "# === SSL/VPN FIXES ===\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONHTTPSVERIFY\"] = \"0\"\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# === MAIN IMPORTS ===\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# === YAHOO IMPORTS (with error handling) ===\n",
    "try:\n",
    "    from yahooquery import Ticker\n",
    "\n",
    "    print(\"yahooquery loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"yahooquery failed: {e}\")\n",
    "    Ticker = None\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "\n",
    "    print(\"yfinance loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"yfinance failed: {e}\")\n",
    "    yf = None\n",
    "\n",
    "from src.setup import *\n",
    "from src.fetch import get_combined_universe\n",
    "\n",
    "print(\"\\nAll imports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38cad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PRICE = 2.00  # Stock price must be at least $2 (avoid \"penny stocks\")\n",
    "MIN_VOLUME = 1_000_000  # At least 1,000,000 shares traded per day (on average)\n",
    "\n",
    "MIN_CAP = 300_000_000  # Market cap at least $300 million (company value)\n",
    "# Market Cap = Stock Price Ã— Number of Shares\n",
    "MIN_CURRENT_RATIO = 1.2  # Current Ratio must be > 1.2\n",
    "# Current Ratio = Current Assets / Current Liabilities\n",
    "# If > 1, the company can pay its short-term bills\n",
    "MAX_PE_RATIO = 100.0  # P/E ratio must be less than 100\n",
    "# P/E = Price / Earnings Per Share\n",
    "\n",
    "\n",
    "# 4. SAFETY THRESHOLDS - Additional quality filters\n",
    "# -------------------------------------------------\n",
    "MIN_INTEREST_COVERAGE = (\n",
    "    1.5  # Interest Coverage > 1.5 means company earns 1.5x what it owes in interest\n",
    ")\n",
    "# Interest Coverage = EBIT / Interest Expense\n",
    "# If < 1, company can't pay its interest bills = bad!\n",
    "MIN_ROIC = 0.05  # ROIC (Return on Invested Capital) > 5%\n",
    "# ROIC = Operating Profit / Capital Invested\n",
    "# Shows how well management uses money to generate returns\n",
    "FORTRESS_MARGIN_THRESHOLD = 0.05  # Operating Margin > 5% for \"Fortress\" (best) tier\n",
    "# Operating Margin = Operating Income / Revenue\n",
    "# Shows what % of sales becomes actual profit\n",
    "\n",
    "# Sectors we want to EXCLUDE (skip)\n",
    "# Financial Services and Real Estate have very different financial structures\n",
    "EXCLUDED_SECTORS = [\"Financial Services\", \"Real Estate\"]\n",
    "\n",
    "CACHE_EXPIRY_DAYS = 30  # Re-fetch data if our saved data is older than 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5361c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 1: Fetching North American Universe ---\n",
      "   -> Found 6008 US stocks.\n",
      "\n",
      "--- STEP 2: Running 'Lightweight' Filter on 6008 stocks ---\n",
      " -> Processing Batch 1/13...\n",
      " -> Processing Batch 6/13...\n",
      " -> Processing Batch 11/13...\n",
      "\n",
      " Step 2 Complete. 554 stocks passed basic filters.\n",
      "\n",
      "--- STEP 3: Fetching Deep Financials for 554 Survivors ---\n",
      " -> Analyzing 1/554: A...\n",
      " -> Analyzing 21/554: ALGN...\n",
      " -> Analyzing 41/554: AQN...\n",
      " -> Analyzing 61/554: AXL...\n",
      " -> Analyzing 81/554: BMY...\n",
      " -> Analyzing 101/554: CCC...\n",
      " -> Analyzing 121/554: CNXC...\n",
      " -> Analyzing 141/554: CXM...\n",
      " -> Analyzing 161/554: DT...\n",
      " -> Analyzing 181/554: ETN...\n",
      " -> Analyzing 201/554: FOLD...\n",
      " -> Analyzing 221/554: GIL...\n",
      " -> Analyzing 241/554: HALO...\n",
      " -> Analyzing 261/554: HSY...\n",
      " -> Analyzing 281/554: ITGR...\n",
      " -> Analyzing 301/554: LFST...\n",
      " -> Analyzing 321/554: MHK...\n",
      " -> Analyzing 341/554: NFLX...\n",
      " -> Analyzing 361/554: OLLI...\n",
      " -> Analyzing 381/554: PGY...\n",
      " -> Analyzing 401/554: QXO...\n",
      " -> Analyzing 421/554: RVTY...\n",
      " -> Analyzing 441/554: SMCI...\n",
      " -> Analyzing 461/554: STZ...\n",
      " -> Analyzing 481/554: TOL...\n",
      " -> Analyzing 501/554: ULS...\n",
      " -> Analyzing 521/554: VSAT...\n",
      " -> Analyzing 541/554: XPRO...\n",
      "\n",
      "============================================================\n",
      "RESULTS GENERATED\n",
      "============================================================\n",
      "1. FORTRESS (220): Saved to 'YfinanceDataDump\\fortress_stocks.csv'\n",
      "2. STRONG   (107): Saved to 'YfinanceDataDump\\strong_stocks.csv'\n",
      "3. RISKY    (223): Saved to 'YfinanceDataDump\\risky_stocks.csv'\n",
      "\n",
      "--- FORTRESS PREVIEW ---\n",
      "    Ticker      Tier    Price    P/E                  Sector  Z-Score  ROIC %  Op Margin %  Avg Margin (4Y)  Curr Ratio  Int Cov  Mkt Cap (B)\n",
      "530    WPM  Fortress  135.350  61.24         Basic Materials   224.89    8.72        66.54            50.89       8.089  2269.82        61.53\n",
      "344   NVDA  Fortress  186.105  46.07              Technology    89.42   90.08        63.17            43.63       4.468   341.19      4531.10\n",
      "276   ISRG  Fortress  535.068  70.96              Healthcare    53.70   13.82        30.33            27.54       4.728   100.00       191.81\n",
      "404   RGLD  Fortress  265.120  36.37         Basic Materials    52.53   13.18        50.53            51.72       3.516    44.71        22.38\n",
      "408   RMBS  Fortress  107.990  51.42              Technology    32.66   15.97        35.43            19.68      11.609   142.27        11.63\n",
      "184   FAST  Fortress   43.740  41.26             Industrials    32.25   37.78        20.70            20.47       4.259   207.59        50.22\n",
      "123   CPRT  Fortress   41.040  25.18             Industrials    29.73   18.04        37.29            37.83       7.939      NaN        39.73\n",
      "320   MNST  Fortress   78.170  44.41      Consumer Defensive    29.56   29.15        30.74            27.67       3.185   100.00        76.37\n",
      "47     ASM  Fortress    7.040  50.29         Basic Materials    28.88   11.12        32.56             6.68       2.754    38.26         1.10\n",
      "153   DOCS  Fortress   41.260  33.01              Healthcare    27.80   20.77        38.55            34.85       7.786   100.00         7.77\n",
      "29    ANET  Fortress  129.830  49.18              Technology    26.95   26.03        42.38            36.70       3.254   100.00       163.49\n",
      "466    TER  Fortress  228.145  82.66              Technology    26.54   19.87        18.89            24.67       1.759   170.80        36.29\n",
      "35     APP  Fortress  568.760  67.15  Communication Services    26.42   39.37        76.80            15.80       3.250     5.95       192.38\n",
      "229   GOOG  Fortress  330.340  32.58  Communication Services    21.73   33.25        30.51            29.14       1.747   448.07      3987.81\n",
      "483   TSEM  Fortress  129.830  75.05              Technology    21.48    7.92        12.78            14.02       6.610    54.97        14.60\n"
     ]
    }
   ],
   "source": [
    "from src.filters import get_initial_survivors\n",
    "from src.financial_analysis import get_advanced_metrics\n",
    "\n",
    "# STEP 1: Get list of all US stocks\n",
    "tickers = get_combined_universe()\n",
    "\n",
    "if len(tickers) > 0:\n",
    "    # STEP 2: Apply quick filters\n",
    "    survivors_df = get_initial_survivors(\n",
    "        tickers,\n",
    "        MIN_PRICE,\n",
    "        MIN_VOLUME,\n",
    "        MIN_CAP,\n",
    "        MIN_CURRENT_RATIO,\n",
    "        EXCLUDED_SECTORS,\n",
    "        MAX_PE_RATIO,\n",
    "    )\n",
    "\n",
    "    if not survivors_df.empty:\n",
    "        print(f\"\\n Step 2 Complete. {len(survivors_df)} stocks passed basic filters.\")\n",
    "\n",
    "        # STEP 3: Deep financial analysis\n",
    "        final_results = get_advanced_metrics(survivors_df, CACHE_EXPIRY_DAYS,FORTRESS_MARGIN_THRESHOLD,MIN_INTEREST_COVERAGE,MIN_ROIC,calculate_altman_z_yfinance,save_cache)\n",
    "\n",
    "        if not final_results.empty:\n",
    "            # Sort results: First by Tier (alphabetically), then by Z-Score (highest first)\n",
    "            final_results = final_results.sort_values(\n",
    "                by=[\"Tier\", \"Z-Score\"],\n",
    "                ascending=[True, False],  # True = A-Z, False = highest first\n",
    "            )\n",
    "\n",
    "            # Split into three categories based on tier\n",
    "            fortress_df = final_results[final_results[\"Tier\"] == \"Fortress\"].copy()\n",
    "            strong_df = final_results[final_results[\"Tier\"] == \"Strong\"].copy()\n",
    "            risky_df = final_results[final_results[\"Tier\"] == \"Risky\"].copy()\n",
    "\n",
    "            # Save to CSV files (spreadsheet format)\n",
    "            try:\n",
    "                fortress_df.to_csv(\n",
    "                    FORTRESS_CSV, index=False\n",
    "                )  # index=False means don't save row numbers\n",
    "                strong_df.to_csv(STRONG_CSV, index=False)\n",
    "                risky_df.to_csv(RISKY_CSV, index=False)\n",
    "\n",
    "                print(\"\\n\" + \"=\" * 60)\n",
    "                print(\"RESULTS GENERATED\")\n",
    "                print(\"=\" * 60)\n",
    "                print(f\"1. FORTRESS ({len(fortress_df)}): Saved to '{FORTRESS_CSV}'\")\n",
    "                print(f\"2. STRONG   ({len(strong_df)}): Saved to '{STRONG_CSV}'\")\n",
    "                print(f\"3. RISKY    ({len(risky_df)}): Saved to '{RISKY_CSV}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  Error Saving Files: {e}\")\n",
    "\n",
    "            # Set display options for pandas (so we can see more data)\n",
    "            pd.set_option(\"display.max_rows\", 500)\n",
    "            pd.set_option(\"display.max_columns\", 20)\n",
    "            pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "            # Show preview of fortress stocks\n",
    "            print(\"\\n--- FORTRESS PREVIEW ---\")\n",
    "            print(fortress_df.head(15))  # .head(15) shows first 15 rows\n",
    "        else:\n",
    "            print(\"No stocks passed the deep financial analysis.\")\n",
    "    else:\n",
    "        print(\"No stocks passed the initial lightweight filter.\")\n",
    "else:\n",
    "    print(\"Could not fetch ticker universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3723f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FORTRESS PULLBACK: Scanning 220 stocks (RSI < 40) ---\n",
      "\n",
      "SUCCESS: Pullback candidates saved to 'YfinanceDataDump/Fortress_Pullback_Candidates_USA.csv'\n",
      "Original Fortress Count: 220 -> Pullback Count: 10\n",
      "\n",
      "--- FORTRESS STOCKS 'ON SALE' ---\n",
      "  Ticker    Price  RSI_14  SMA_200  Dist_to_SMA_%      Tier\n",
      "7   WLTH    9.500   14.38      NaN            NaN  Fortress\n",
      "8   VSNT   33.040   22.74      NaN            NaN  Fortress\n",
      "5   QCOM  159.420   32.30   158.62           0.50  Fortress\n",
      "0   ISRG  535.068   34.70   514.74           3.94  Fortress\n",
      "3   NBIX  132.390   35.37   132.19           0.15  Fortress\n",
      "4    ULS   75.000   35.38    71.79           4.47  Fortress\n",
      "1    APP  568.760   35.68   482.72          17.82  Fortress\n",
      "9   TGNA   18.850   36.52    18.35           2.73  Fortress\n",
      "2     ZM   80.960   36.79    80.14           1.03  Fortress\n",
      "6   URBN   69.480   38.30    68.67           1.17  Fortress\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6a: FORTRESS PULLBACK SCAN (RSI + TREND)\n",
    "# =============================================================================\n",
    "# This scan looks for high-quality \"Fortress\" stocks that are:\n",
    "# 1. In a long-term Uptrend (Price > 200 SMA)\n",
    "# 2. In a short-term Pullback (RSI < 40)\n",
    "# This is the \"Buy the Dip\" strategy for quality assets.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_fortress_pullback(df_input, rsi_threshold=40):\n",
    "    \"\"\"\n",
    "    Calculates RSI (14-day) and 200-day SMA.\n",
    "    Filters for stocks where Price > SMA200 AND RSI < Threshold.\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Fortress Pullback] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(\n",
    "        f\"\\n--- FORTRESS PULLBACK: Scanning {len(tickers)} stocks (RSI < {rsi_threshold}) ---\"\n",
    "    )\n",
    "\n",
    "    # 1. Fetch History (Need ~1 year for SMA 200)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pullback_candidates = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle Data Structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need enough data\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history.\")\n",
    "                continue\n",
    "\n",
    "            # 2. Calculate 200-Day SMA (Trend Filter)\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # CONDITION 1: Must be in an Uptrend\n",
    "            if current_price < sma_200:\n",
    "                continue\n",
    "\n",
    "            # 3. Calculate RSI (14-Day)\n",
    "            # Calculate daily price changes\n",
    "            delta = df_hist[\"Close\"].diff()\n",
    "\n",
    "            # Separate gains and losses\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "            # Calculate Exponential Moving Average (Wilder's Smoothing usually uses alpha=1/14)\n",
    "            avg_gain = gain.ewm(com=13, adjust=False).mean()\n",
    "            avg_loss = loss.ewm(com=13, adjust=False).mean()\n",
    "\n",
    "            # Calculate RS and RSI\n",
    "            rs = avg_gain / avg_loss\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "            current_rsi = rsi.iloc[-1]\n",
    "\n",
    "            # CONDITION 2: Must be Oversold (Pullback)\n",
    "            if current_rsi < rsi_threshold:\n",
    "                # Get base data\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                base_row[\"RSI_14\"] = round(current_rsi, 2)\n",
    "                base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "                # Distance from SMA (Buy Zone Depth)\n",
    "                base_row[\"Dist_to_SMA_%\"] = round(\n",
    "                    ((current_price - sma_200) / sma_200) * 100, 2\n",
    "                )\n",
    "\n",
    "                pullback_candidates.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(pullback_candidates)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# Check if Fortress DataFrame exists\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "\n",
    "    # Run the scan\n",
    "    # We use 40 as the threshold because quality stocks rarely drop to 30\n",
    "    Fortress_Dip_DF = apply_fortress_pullback(fortress_df, rsi_threshold=40)\n",
    "\n",
    "    if not Fortress_Dip_DF.empty:\n",
    "        # Sort by Lowest RSI (Deepest Dip)\n",
    "        Fortress_Dip_DF = Fortress_Dip_DF.sort_values(by=\"RSI_14\", ascending=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        PULLBACK_CSV = \"YfinanceDataDump/Fortress_Pullback_Candidates_USA.csv\"\n",
    "        Fortress_Dip_DF.to_csv(PULLBACK_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Pullback candidates saved to '{PULLBACK_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Fortress Count: {len(fortress_df)} -> Pullback Count: {len(Fortress_Dip_DF)}\"\n",
    "        )\n",
    "\n",
    "        cols = [\"Ticker\", \"Price\", \"RSI_14\", \"SMA_200\", \"Dist_to_SMA_%\", \"Tier\"]\n",
    "        print(\"\\n--- FORTRESS STOCKS 'ON SALE' ---\")\n",
    "        print(Fortress_Dip_DF[cols].head(15))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. No Fortress stocks are currently oversold (RSI < 40).\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Error: 'fortress_df' not found. Please run the Main Execution cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ee3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: Fetching Analyst Ratings for 220 Stocks ---\n",
      "    (Fetching serially to avoid throttling...)\n",
      " -> Analyst Scan 1/220: WPM...\n",
      " -> Analyst Scan 11/220: ANET...\n",
      " -> Analyst Scan 21/220: CPRX...\n",
      " -> Analyst Scan 31/220: META...\n",
      " -> Analyst Scan 41/220: LLY...\n",
      " -> Analyst Scan 51/220: TXN...\n",
      " -> Analyst Scan 61/220: REGN...\n",
      " -> Analyst Scan 71/220: AEM...\n",
      " -> Analyst Scan 81/220: ULS...\n",
      " -> Analyst Scan 91/220: PAAS...\n",
      " -> Analyst Scan 101/220: ABT...\n",
      " -> Analyst Scan 111/220: ECL...\n",
      " -> Analyst Scan 121/220: LRN...\n",
      " -> Analyst Scan 131/220: ATI...\n",
      " -> Analyst Scan 141/220: DKS...\n",
      " -> Analyst Scan 151/220: GNRC...\n",
      " -> Analyst Scan 161/220: TOL...\n",
      " -> Analyst Scan 171/220: TMHC...\n",
      " -> Analyst Scan 181/220: TPR...\n",
      " -> Analyst Scan 191/220: BLDR...\n",
      " -> Analyst Scan 201/220: BURL...\n",
      " -> Analyst Scan 211/220: BIRK...\n",
      "\n",
      "  Analyst Scan Complete!\n",
      "Found 186 stocks with Buy Ratings (Score < 2.5)\n",
      "Saved to 'YfinanceDataDump\\Analyst_Fortress_Picks.csv'\n",
      "    Ticker    Price  Analyst_Rating  Upside_%  Target_Price      Tier\n",
      "16    CORT   34.730         2.16667    162.02     91.000000  Fortress\n",
      "46    SGHC    9.940         1.25000     77.31     17.625000  Fortress\n",
      "147   WLTH    9.500         2.14286     73.68     16.500000  Fortress\n",
      "124    TTD   35.477         2.13158     67.71     59.500000  Fortress\n",
      "7     DOCS   41.260         1.95000     57.78     65.100000  Fortress\n",
      "179   BIRK   38.470         1.56522     55.00     59.630283  Fortress\n",
      "83    BRBR   23.910         1.73333     53.85     36.785710  Fortress\n",
      "17    CPRX   22.700         1.00000     53.56     34.857140  Fortress\n",
      "104    LRN   69.710         2.00000     50.62    105.000000  Fortress\n",
      "88      DT   39.880         1.60000     48.27     59.129030  Fortress\n",
      "61    INTU  545.290         1.71429     45.44    793.050600  Fortress\n",
      "102    BSX   88.070         1.26471     41.26    124.406250  Fortress\n",
      "176    PDD  106.703         1.75610     39.86    149.233580  Fortress\n",
      "36    NFLX   88.000         1.91111     39.72    122.957250  Fortress\n",
      "15    VEEV  222.210         2.00000     39.33    309.610000  Fortress\n",
      "67    ALKS   31.630         1.52941     38.12     43.687500  Fortress\n",
      "64    VNOM   36.940         1.38889     37.31     50.722220  Fortress\n",
      "169   SMPL   20.930         2.00000     36.17     28.500000  Fortress\n",
      "1     NVDA  186.105         1.34375     35.95    253.017930  Fortress\n",
      "45    NBIX  132.390         1.44444     35.65    179.589260  Fortress\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: STEP 4 - ANALYST RATINGS FILTER\n",
    "# =============================================================================\n",
    "# This adds another layer of analysis: what do professional analysts think?\n",
    "# Analyst Rating Scale (typically):\n",
    "#   1.0 = Strong Buy\n",
    "#   2.0 = Buy\n",
    "#   3.0 = Hold\n",
    "#   4.0 = Sell\n",
    "#   5.0 = Strong Sell\n",
    "\n",
    "\n",
    "def get_analyst_fortress_from_var(df_input):\n",
    "    \"\"\"\n",
    "    Fetch analyst ratings for stocks and filter for those rated \"Buy\" or better.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks with analyst ratings and upside potential\n",
    "    \"\"\"\n",
    "    working_df = df_input.copy()\n",
    "    tickers = working_df[\"Ticker\"].tolist()\n",
    "\n",
    "    print(f\"\\n--- STEP 4: Fetching Analyst Ratings for {len(tickers)} Stocks ---\")\n",
    "    print(\"    (Fetching serially to avoid throttling...)\")\n",
    "\n",
    "    analyst_data = []\n",
    "\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        # Print progress every 10 stocks\n",
    "        if i % 10 == 0:\n",
    "            print(f\" -> Analyst Scan {i+1}/{len(tickers)}: {ticker}...\")\n",
    "\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info  # Get all available info for the stock\n",
    "\n",
    "            # Extract analyst recommendation (1.0 to 5.0 scale)\n",
    "            rec_mean = info.get(\"recommendationMean\")\n",
    "            target_price = info.get(\"targetMeanPrice\")  # Average price target\n",
    "            current_price = info.get(\"currentPrice\")\n",
    "\n",
    "            # Filter: Only keep stocks rated 2.5 or better (Buy or Strong Buy)\n",
    "            if rec_mean is None or rec_mean > 2.5:\n",
    "                continue\n",
    "\n",
    "            # Calculate upside potential\n",
    "            # Upside = (Target - Current) / Current * 100\n",
    "            upside = 0\n",
    "            if target_price and current_price:\n",
    "                upside = round(\n",
    "                    ((target_price - current_price) / current_price) * 100, 2\n",
    "                )\n",
    "\n",
    "            # Get the original data and add new columns\n",
    "            base_row = working_df[working_df[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "            base_row[\"Analyst_Rating\"] = rec_mean\n",
    "            base_row[\"Target_Price\"] = target_price\n",
    "            base_row[\"Upside_%\"] = upside\n",
    "\n",
    "            analyst_data.append(base_row)\n",
    "            time.sleep(0.2)  # Small delay to not be timed out of Yahoo's servers\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(analyst_data)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTE THE ANALYST FILTER\n",
    "# ==========================================\n",
    "\n",
    "# Check if fortress_df exists from the previous step\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "\n",
    "    # Run the function\n",
    "    Analyst_Fortress_DF = get_analyst_fortress_from_var(fortress_df)\n",
    "\n",
    "    if not Analyst_Fortress_DF.empty:\n",
    "        # Sort by highest upside potential\n",
    "        Analyst_Fortress_DF = Analyst_Fortress_DF.sort_values(\n",
    "            by=\"Upside_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        print(\"\\n  Analyst Scan Complete!\")\n",
    "        print(f\"Found {len(Analyst_Fortress_DF)} stocks with Buy Ratings (Score < 2.5)\")\n",
    "\n",
    "        # Save to CSV\n",
    "        Analyst_Fortress_DF.to_csv(ANALYST_CSV, index=False)\n",
    "        print(f\"Saved to '{ANALYST_CSV}'\")\n",
    "\n",
    "        # Show top picks\n",
    "        cols = [\"Ticker\", \"Price\", \"Analyst_Rating\", \"Upside_%\", \"Target_Price\", \"Tier\"]\n",
    "        print(Analyst_Fortress_DF[cols].head())\n",
    "    else:\n",
    "        print(\"No stocks passed the Analyst filter.\")\n",
    "else:\n",
    "    print(\"  'fortress_df' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca466fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 5: Warren Buffett 'Below NAV' Scan ---\n",
      "    Scanning 550 candidates for Deep Value...\n",
      "    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\n",
      "\n",
      "============================================================\n",
      "BUFFETT SCAN COMPLETE\n",
      "============================================================\n",
      "Found 18 Deep Value Stocks\n",
      "\n",
      "--- DEEP VALUE PICKS ---\n",
      "  Ticker  Price  P/B Ratio  ROE %  Debt/Eq %                  Sector      Tier\n",
      "9   ACHC  11.68       0.34   3.69      74.49              Healthcare     Risky\n",
      "0   GMAB  32.25       0.35  29.41       2.47              Healthcare  Fortress\n",
      "8     KT  19.49       0.40   5.08      60.17  Communication Services     Risky\n",
      "5    SSL   6.31       0.44   5.07      76.56         Basic Materials     Risky\n",
      "7   ANGI  12.49       0.55   3.42      54.03  Communication Services     Risky\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: BUFFETT VALUE SCAN\n",
    "# =============================================================================\n",
    "# This filter looks for stocks Warren Buffett might like:\n",
    "# - Trading BELOW book value (P/B < 1.0) means you're buying $1 of assets for less than $1\n",
    "# - Positive Return on Equity (ROE) shows the company is profitable\n",
    "# - Reasonable debt levels (Debt/Equity < 100%)\n",
    "\n",
    "\n",
    "def get_buffett_value_picks(df_input):\n",
    "    \"\"\"\n",
    "    Find deep value stocks trading below their book value.\n",
    "\n",
    "    Book Value = Total Assets - Total Liabilities\n",
    "    P/B Ratio = Stock Price / Book Value per Share\n",
    "\n",
    "    If P/B < 1.0, you're theoretically buying the company for less than\n",
    "    what it would be worth if you sold all its assets and paid all debts.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Deep value stocks sorted by P/B ratio\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- STEP 5: Warren Buffett 'Below NAV' Scan ---\")\n",
    "    print(f\"    Scanning {len(df_input)} candidates for Deep Value...\")\n",
    "    print(\n",
    "        \"    Criteria: P/B < 1.0 (Below Book) | ROE > 0% (Profitable) | Debt/Eq < 100%\"\n",
    "    )\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    buffett_candidates = []\n",
    "\n",
    "    # Process in chunks for speed\n",
    "    chunk_size = 250\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            # Get key statistics and financial data\n",
    "            data = yq.get_modules(\"defaultKeyStatistics financialData\")\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if isinstance(data, dict) and symbol in data:\n",
    "                    try:\n",
    "                        stats = data[symbol].get(\"defaultKeyStatistics\", {})\n",
    "                        fin = data[symbol].get(\"financialData\", {})\n",
    "\n",
    "                        # 1. Price to Book < 1.0 (The Core \"Value\" Rule)\n",
    "                        pb = stats.get(\"priceToBook\")\n",
    "                        if pb is None or pb >= 1.0 or pb <= 0:\n",
    "                            continue\n",
    "\n",
    "                        # 2. Positive ROE (Return on Equity - company makes money)\n",
    "                        roe = fin.get(\"returnOnEquity\", 0)\n",
    "                        if roe is None or roe <= 0:\n",
    "                            continue\n",
    "\n",
    "                        # 3. Reasonable Debt (not overleveraged)\n",
    "                        de = fin.get(\"debtToEquity\", 0)\n",
    "                        if de is None or de > 100:\n",
    "                            continue\n",
    "\n",
    "                        # Get base data and add value metrics\n",
    "                        base_row = (\n",
    "                            df_input[df_input[\"Ticker\"] == symbol].iloc[0].to_dict()\n",
    "                        )\n",
    "                        base_row[\"P/B Ratio\"] = round(pb, 2)\n",
    "                        base_row[\"ROE %\"] = round(roe * 100, 2)\n",
    "                        base_row[\"Debt/Eq %\"] = round(de, 2)\n",
    "\n",
    "                        buffett_candidates.append(base_row)\n",
    "\n",
    "                    except:\n",
    "                        print(f\"   [Error] Processing {symbol} data.\")\n",
    "                        continue\n",
    "        except:\n",
    "            print(\"   [Error] Fetching chunk data.\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(buffett_candidates)\n",
    "\n",
    "\n",
    "# Run the Buffett scan\n",
    "if \"final_results\" in locals() and not final_results.empty:\n",
    "    Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "\n",
    "    if not Buffett_Value_DF.empty:\n",
    "        Buffett_Value_DF = Buffett_Value_DF.sort_values(by=\"P/B Ratio\", ascending=True)\n",
    "        Buffett_Value_DF.to_csv(BUFFETT_CSV, index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"BUFFETT SCAN COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Found {len(Buffett_Value_DF)} Deep Value Stocks\")\n",
    "\n",
    "        cols = [\"Ticker\", \"Price\", \"P/B Ratio\", \"ROE %\", \"Debt/Eq %\", \"Sector\", \"Tier\"]\n",
    "        print(\"\\n--- DEEP VALUE PICKS ---\")\n",
    "        print(Buffett_Value_DF[cols].head())\n",
    "    else:\n",
    "        print(\"\\n  No stocks passed the Buffett filter.\")\n",
    "else:\n",
    "    print(\" 'final_results' not found. Please run Steps 1-3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca01e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TREND ALIGNMENT: Checking 200-Day SMA for 18 Buffett candidates ---\n",
      "\n",
      "SUCCESS: Filtered list saved to 'YfinanceDataDump/Buffett_Trend_Aligned_USA.csv'\n",
      "Original Count: 18 -> Trend Aligned Count: 15\n",
      "\n",
      "--- BUFFETT STOCKS IN UPTREND ---\n",
      "   Ticker  Price  P/B Ratio  SMA_200  Trend_Dist_%      Tier\n",
      "1      KT  19.49       0.40    19.26          1.17     Risky\n",
      "11    SXC   7.91       0.96     7.79          1.59    Strong\n",
      "14   TMHC  63.27       1.00    61.74          2.47  Fortress\n",
      "12   TGNA  18.85       0.97    18.35          2.73  Fortress\n",
      "13    KBH  61.32       0.99    58.20          5.37     Risky\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8a: BUFFETT TREND ALIGNMENT (200-DAY SMA)\n",
    "# =============================================================================\n",
    "# This cell takes the 'Deep Value' candidates found in the previous step and\n",
    "# filters out any that are in a long-term downtrend (Price < 200-Day SMA).\n",
    "# This helps avoid \"Value Traps\" - stocks that are cheap because they are dying.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_trend_alignment(df_input):\n",
    "    \"\"\"\n",
    "    Calculates the 200-day SMA and filters for stocks trading ABOVE it.\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Trend Alignment] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(\n",
    "        f\"\\n--- TREND ALIGNMENT: Checking 200-Day SMA for {len(tickers)} Buffett candidates ---\"\n",
    "    )\n",
    "\n",
    "    # 1. Fetch History (Need at least 200 trading days, so 1y is perfect)\n",
    "    try:\n",
    "        # group_by='ticker' ensures the dataframe structure is consistent\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    trend_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure: if multiple tickers, it uses MultiIndex\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                # If only one ticker, yfinance returns a flat dataframe\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need at least 200 days of data to calculate the SMA\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history (<200 days).\")\n",
    "                continue\n",
    "\n",
    "            # 2. Calculate 200-Day SMA\n",
    "            # .rolling(window=200).mean() averages the last 200 closing prices\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # 3. The Filter Condition: Price > SMA 200\n",
    "            # We want stocks that have \"reclaimed\" their trend\n",
    "            is_uptrend = current_price > sma_200\n",
    "\n",
    "            # Calculate how far above/below the SMA it is (as a %)\n",
    "            distance_pct = round(((current_price - sma_200) / sma_200) * 100, 2)\n",
    "\n",
    "            if is_uptrend:\n",
    "                # Get the original row data from the Buffett DataFrame\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                # Add technical metrics to the row\n",
    "                base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "                base_row[\"Trend_Dist_%\"] = distance_pct\n",
    "\n",
    "                trend_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Processing {ticker}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create the new filtered DataFrame\n",
    "    return pd.DataFrame(trend_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# Check if the Buffett DataFrame exists from the previous cell\n",
    "if \"Buffett_Value_DF\" in locals() and not Buffett_Value_DF.empty:\n",
    "\n",
    "    # Run the filter\n",
    "    Buffett_Trend_DF = apply_trend_alignment(Buffett_Value_DF)\n",
    "\n",
    "    if not Buffett_Trend_DF.empty:\n",
    "        # Sort by trend strength (how far above the 200 SMA they are)\n",
    "        Buffett_Trend_DF = Buffett_Trend_DF.sort_values(\n",
    "            by=\"Trend_Dist_%\", ascending=True\n",
    "        )\n",
    "\n",
    "        # Save to a new CSV\n",
    "        TREND_CSV = \"YfinanceDataDump/Buffett_Trend_Aligned_USA.csv\"\n",
    "        Buffett_Trend_DF.to_csv(TREND_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Filtered list saved to '{TREND_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Count: {len(Buffett_Value_DF)} -> Trend Aligned Count: {len(Buffett_Trend_DF)}\"\n",
    "        )\n",
    "\n",
    "        # Display the survivors\n",
    "        cols = [\"Ticker\", \"Price\", \"P/B Ratio\", \"SMA_200\", \"Trend_Dist_%\", \"Tier\"]\n",
    "        print(\"\\n--- BUFFETT STOCKS IN UPTREND ---\")\n",
    "        print(Buffett_Trend_DF[cols].head(5))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. All Buffett picks are currently in a downtrend.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Error: 'Buffett_Value_DF' not found. Please run the Buffett Scan cell first.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "065392ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scanning 220 stocks for Insider Buying...\n",
      "Created 'Fortress_insiders' with 12 rows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6b26f022-9020-41a9-8d1c-618aaed66009",
       "rows": [
        [
         "0",
         "MU",
         "362.75",
         "3",
         "167433.0"
        ],
        [
         "1",
         "CDE",
         "22.58",
         "21",
         "1650770.0"
        ],
        [
         "2",
         "HXL",
         "82.59",
         "6",
         "14327.0"
        ],
        [
         "3",
         "GIL",
         "63.22",
         "105",
         "1426104.0"
        ],
        [
         "4",
         "SHLS",
         "9.27",
         "3",
         "8335.0"
        ],
        [
         "5",
         "CGAU",
         "16.13",
         "87",
         "4297682.0"
        ],
        [
         "6",
         "RAL",
         "53.53",
         "1",
         "2000.0"
        ],
        [
         "7",
         "TTD",
         "35.477",
         "10",
         "3557415.0"
        ],
        [
         "8",
         "FSM",
         "10.42",
         "10",
         "2116207.0"
        ],
        [
         "9",
         "OPCH",
         "36.03",
         "8",
         "18954.0"
        ],
        [
         "10",
         "CRH",
         "122.97",
         "3",
         "413316.0"
        ],
        [
         "11",
         "HSIC",
         "79.98",
         "5",
         "16257.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MU</td>\n",
       "      <td>362.750</td>\n",
       "      <td>3</td>\n",
       "      <td>167433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDE</td>\n",
       "      <td>22.580</td>\n",
       "      <td>21</td>\n",
       "      <td>1650770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HXL</td>\n",
       "      <td>82.590</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIL</td>\n",
       "      <td>63.220</td>\n",
       "      <td>105</td>\n",
       "      <td>1426104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>9.270</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CGAU</td>\n",
       "      <td>16.130</td>\n",
       "      <td>87</td>\n",
       "      <td>4297682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RAL</td>\n",
       "      <td>53.530</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TTD</td>\n",
       "      <td>35.477</td>\n",
       "      <td>10</td>\n",
       "      <td>3557415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FSM</td>\n",
       "      <td>10.420</td>\n",
       "      <td>10</td>\n",
       "      <td>2116207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPCH</td>\n",
       "      <td>36.030</td>\n",
       "      <td>8</td>\n",
       "      <td>18954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CRH</td>\n",
       "      <td>122.970</td>\n",
       "      <td>3</td>\n",
       "      <td>413316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HSIC</td>\n",
       "      <td>79.980</td>\n",
       "      <td>5</td>\n",
       "      <td>16257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0      MU        362.750                   3           167433.0\n",
       "1     CDE         22.580                  21          1650770.0\n",
       "2     HXL         82.590                   6            14327.0\n",
       "3     GIL         63.220                 105          1426104.0\n",
       "4    SHLS          9.270                   3             8335.0\n",
       "5    CGAU         16.130                  87          4297682.0\n",
       "6     RAL         53.530                   1             2000.0\n",
       "7     TTD         35.477                  10          3557415.0\n",
       "8     FSM         10.420                  10          2116207.0\n",
       "9    OPCH         36.030                   8            18954.0\n",
       "10    CRH        122.970                   3           413316.0\n",
       "11   HSIC         79.980                   5            16257.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: INSIDER TRADING FILTER\n",
    "# =============================================================================\n",
    "# Insiders (executives, directors, major shareholders) sometimes have better\n",
    "# information about their company. When they BUY their own stock, it can be\n",
    "# a positive sign. When they SELL, it might be neutral (paying taxes) or negative.\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def filter_for_insider_buying(tickers):\n",
    "    \"\"\"\n",
    "    Find stocks where company insiders are NET BUYERS.\n",
    "\n",
    "    Net Buying = Total shares bought - Total shares sold\n",
    "    If positive, insiders are accumulating shares (bullish signal).\n",
    "\n",
    "    Args:\n",
    "        tickers: List of stock symbols to check\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks with positive insider buying\n",
    "    \"\"\"\n",
    "    print(f\" Scanning {len(tickers)} stocks for Insider Buying...\")\n",
    "    insider_picks = []\n",
    "\n",
    "    # Process in smaller chunks to avoid timeout\n",
    "    chunk_size = 25\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "\n",
    "            # Fetch insider transaction data\n",
    "            df_insiders = yq.insider_transactions\n",
    "\n",
    "            # Fetch current prices\n",
    "            price_data = yq.price\n",
    "\n",
    "            # Skip if no data\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, \"reset_index\"):\n",
    "                continue\n",
    "\n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders[\"symbol\"].values:\n",
    "                    continue\n",
    "\n",
    "                # Get transactions for this stock\n",
    "                stock_tx = df_insiders[df_insiders[\"symbol\"] == symbol].copy()\n",
    "\n",
    "                # Separate purchases and sales\n",
    "                # The text typically says \"Purchase\" or \"Sale\"\n",
    "                buys = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.contains(\"Purchase\", case=False, na=False)\n",
    "                ]\n",
    "                sells = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.contains(\"Sale\", case=False, na=False)\n",
    "                ]\n",
    "\n",
    "                # Calculate total buy/sell volume\n",
    "                buy_vol = buys[\"shares\"].sum() if not buys.empty else 0\n",
    "                sell_vol = sells[\"shares\"].sum() if not sells.empty else 0\n",
    "\n",
    "                # Get current price\n",
    "                current_price = None\n",
    "                try:\n",
    "                    if isinstance(price_data, dict) and symbol in price_data:\n",
    "                        current_price = price_data[symbol].get(\n",
    "                            \"regularMarketPrice\", None\n",
    "                        )\n",
    "                except:\n",
    "                    current_price = None\n",
    "\n",
    "                # Only keep if net buying is positive\n",
    "                if buy_vol > sell_vol:\n",
    "                    insider_picks.append(\n",
    "                        {\n",
    "                            \"Ticker\": symbol,\n",
    "                            \"Current_Price\": current_price,\n",
    "                            \"Insider_Buys_Count\": len(buys),\n",
    "                            \"Net_Shares_Bought\": buy_vol - sell_vol,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Processing chunk: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "\n",
    "# Run the insider filter\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df[\"Ticker\"].tolist()\n",
    "\n",
    "else:\n",
    "    print(\"'fortress_df' and 'strong_df' not found.\")\n",
    "\n",
    "Fortress_insiders_1 = filter_for_insider_buying(target_tickers)\n",
    "print(f\"Created 'Fortress_insiders' with {len(Fortress_insiders_1)} rows.\")\n",
    "Fortress_insiders_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8b0427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: 'strong_df' (107 tickers)\n",
      " Scanning 107 stocks for High-Conviction Insider Buying...\n",
      "   [Error] Processing chunk 8: 'symbol'\n",
      "\n",
      "Final Result: Found 12 Strong stocks with 2+ Insider Buys.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9a: INSIDER TRADING FILTER (STRONG LIST ONLY | MIN 2 BUYS)\n",
    "# =============================================================================\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "from yahooquery import Ticker\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def filter_for_strong_insider_buying(tickers):\n",
    "    \"\"\"\n",
    "    Find stocks where insiders are NET BUYERS with HIGH CONVICTION.\n",
    "    Criteria:\n",
    "    1. Net Buying (Buys > Sells)\n",
    "    2. Conviction (At least 2 separate Buy transactions)\n",
    "    \"\"\"\n",
    "    print(f\" Scanning {len(tickers)} stocks for High-Conviction Insider Buying...\")\n",
    "    insider_picks = []\n",
    "\n",
    "    # Conservative chunk size for stability\n",
    "    chunk_size = 15\n",
    "    chunks = [tickers[i : i + chunk_size] for i in range(0, len(tickers), chunk_size)]\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Delay to prevent API blocking \n",
    "            #potentially add a while loop to iterate when a symbol is blocked rety in a couple seconds\n",
    "            time.sleep(5.0)\n",
    "\n",
    "            yq = Ticker(chunk, asynchronous=True)\n",
    "            df_insiders = yq.insider_transactions\n",
    "            price_data = yq.price\n",
    "\n",
    "            if isinstance(df_insiders, dict) or not hasattr(df_insiders, \"reset_index\"):\n",
    "                continue\n",
    "\n",
    "            df_insiders = df_insiders.reset_index()\n",
    "\n",
    "            for symbol in chunk:\n",
    "                if symbol not in df_insiders[\"symbol\"].values:\n",
    "                    continue\n",
    "\n",
    "                stock_tx = df_insiders[df_insiders[\"symbol\"] == symbol].copy()\n",
    "\n",
    "                # Robust lowercase search\n",
    "                buys = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.contains(\"purchase\", na=False)\n",
    "                ]\n",
    "                sells = stock_tx[\n",
    "                    stock_tx[\"transactionText\"]\n",
    "                    .astype(str)\n",
    "                    .str.lower()\n",
    "                    .str.contains(\"sale\", na=False)\n",
    "                ]\n",
    "\n",
    "                # === NEW FILTER: MINIMUM 2 BUY TRANSACTIONS ===\n",
    "                if len(buys) < 2:\n",
    "                    continue\n",
    "\n",
    "                buy_vol = buys[\"shares\"].sum() if not buys.empty else 0\n",
    "                sell_vol = sells[\"shares\"].sum() if not sells.empty else 0\n",
    "\n",
    "                # Logic: Net Positive Buying\n",
    "                if buy_vol > sell_vol:\n",
    "                    current_price = None\n",
    "                    try:\n",
    "                        if isinstance(price_data, dict) and symbol in price_data:\n",
    "                            current_price = price_data[symbol].get(\n",
    "                                \"regularMarketPrice\", None\n",
    "                            )\n",
    "                    except:\n",
    "                        current_price = 0\n",
    "\n",
    "                    insider_picks.append(\n",
    "                        {\n",
    "                            \"Ticker\": symbol,\n",
    "                            \"Current_Price\": current_price,\n",
    "                            \"Insider_Buys_Count\": len(buys),\n",
    "                            \"Net_Shares_Bought\": buy_vol - sell_vol,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Processing chunk {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(insider_picks)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION (STRONG_DF ONLY)\n",
    "# =========================================\n",
    "\n",
    "target_tickers = []\n",
    "\n",
    "# Check for 'strong_df' (or variations of the name)\n",
    "if \"strong_df\" in locals() and not strong_df.empty:\n",
    "    print(f\"Source: 'strong_df' ({len(strong_df)} tickers)\")\n",
    "    target_tickers = strong_df[\"Ticker\"].tolist()\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Error: 'strong_df' variable not found. Please run the Strong Filter cell first.\"\n",
    "    )\n",
    "\n",
    "# Run Scan\n",
    "if len(target_tickers) > 0:\n",
    "    # Remove duplicates and Sort\n",
    "    unique_tickers = sorted(list(set(target_tickers)))\n",
    "\n",
    "    Strong_insiders = filter_for_strong_insider_buying(unique_tickers)\n",
    "\n",
    "    print(\n",
    "        f\"\\nFinal Result: Found {len(Strong_insiders)} Strong stocks with 2+ Insider Buys.\"\n",
    "    )\n",
    "\n",
    "    if not Strong_insiders.empty:\n",
    "        # Sort by Conviction\n",
    "        Strong_insiders = Strong_insiders.sort_values(\n",
    "            by=\"Net_Shares_Bought\", ascending=False\n",
    "        )\n",
    "        Strong_insiders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e51c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current_Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Insider_Buys_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Net_Shares_Bought",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0fe9401a-e722-480b-a15e-e97a1bb48ebd",
       "rows": [
        [
         "0",
         "MU",
         "362.75",
         "3",
         "167433.0"
        ],
        [
         "1",
         "CDE",
         "22.58",
         "21",
         "1650770.0"
        ],
        [
         "2",
         "HXL",
         "82.59",
         "6",
         "14327.0"
        ],
        [
         "3",
         "GIL",
         "63.22",
         "105",
         "1426104.0"
        ],
        [
         "4",
         "SHLS",
         "9.27",
         "3",
         "8335.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Insider_Buys_Count</th>\n",
       "      <th>Net_Shares_Bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MU</td>\n",
       "      <td>362.75</td>\n",
       "      <td>3</td>\n",
       "      <td>167433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDE</td>\n",
       "      <td>22.58</td>\n",
       "      <td>21</td>\n",
       "      <td>1650770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HXL</td>\n",
       "      <td>82.59</td>\n",
       "      <td>6</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIL</td>\n",
       "      <td>63.22</td>\n",
       "      <td>105</td>\n",
       "      <td>1426104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHLS</td>\n",
       "      <td>9.27</td>\n",
       "      <td>3</td>\n",
       "      <td>8335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Current_Price  Insider_Buys_Count  Net_Shares_Bought\n",
       "0     MU         362.75                   3           167433.0\n",
       "1    CDE          22.58                  21          1650770.0\n",
       "2    HXL          82.59                   6            14327.0\n",
       "3    GIL          63.22                 105          1426104.0\n",
       "4   SHLS           9.27                   3             8335.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fortress_insiders = pd.concat([Fortress_insiders_1, Strong_insiders], ignore_index=True)\n",
    "Fortress_insiders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b15b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Analyst-Vetted Insider List\n",
      "\n",
      "--- RVOL CATALYST: Checking volume for 24 Insider picks ---\n",
      "\n",
      "SUCCESS: Catalyst candidates saved to 'YfinanceDataDump/Insider_RVOL_Catalysts_USA.csv'\n",
      "Original Insider Count: 24 -> Catalyst Count: 5\n",
      "\n",
      "--- INSIDER STOCKS WITH HIGH VOLUME SPIKES ---\n",
      "  Ticker  Current_Price  RVOL  Insider_Buys_Count  Net_Shares_Bought\n",
      "4   AXTA          33.57  1.97                   7             7366.0\n",
      "0     MU         362.75  1.66                   3           167433.0\n",
      "2   SHLS           9.27  1.64                   3             8335.0\n",
      "3   HSIC          79.98  1.59                   5            16257.0\n",
      "1    CDE          22.58  1.50                  21          1650770.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9b: RELATIVE VOLUME (RVOL) CATALYST SCAN\n",
    "# =============================================================================\n",
    "# This checks your \"Insider Picks\" for unusual institutional activity.\n",
    "# RVOL > 1.5 means volume is 150% of normal (institutions are active).\n",
    "# RVOL > 2.0 is a massive \"Ignition\" signal.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_rvol_catalyst(df_input, rvol_threshold=1.5):\n",
    "    \"\"\"\n",
    "    Calculates Relative Volume (RVOL).\n",
    "    RVOL = Current Volume / Average Volume (30-day).\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [RVOL Catalyst] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(f\"\\n--- RVOL CATALYST: Checking volume for {len(tickers)} Insider picks ---\")\n",
    "\n",
    "    # 1. Fetch History (Need ~2 months to get a clean 30-day average)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"3mo\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    catalyst_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need at least 30 days of volume data\n",
    "            if len(df_hist) < 30:\n",
    "                continue\n",
    "\n",
    "            # 2. Get Volumes\n",
    "            # Current Volume (Last completed bar)\n",
    "            current_vol = df_hist[\"Volume\"].iloc[-1]\n",
    "\n",
    "            # Average Volume (Previous 30 days, excluding today to avoid skewing the average)\n",
    "            avg_vol = df_hist[\"Volume\"].iloc[-31:-1].mean()\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if avg_vol == 0:\n",
    "                continue\n",
    "\n",
    "            # 3. Calculate RVOL\n",
    "            rvol = current_vol / avg_vol\n",
    "\n",
    "            # 4. Filter\n",
    "            if rvol > rvol_threshold:\n",
    "                # Get base data\n",
    "                base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "                base_row[\"RVOL\"] = round(rvol, 2)\n",
    "                base_row[\"Avg_Vol_30D\"] = int(avg_vol)\n",
    "                base_row[\"Current_Vol\"] = int(current_vol)\n",
    "\n",
    "                catalyst_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Processing {ticker}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(catalyst_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "# We check 'Fortress_insiders' first (Best List)\n",
    "# If that doesn't exist, we check the raw 'Fortress_insiders' list\n",
    "if \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    target_df = Fortress_insiders\n",
    "    print(\"Source: Analyst-Vetted Insider List\")\n",
    "elif \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    target_df = Fortress_insiders\n",
    "    print(\"Source: Raw Insider List\")\n",
    "else:\n",
    "    target_df = pd.DataFrame()\n",
    "\n",
    "if not target_df.empty:\n",
    "    # Run the scan\n",
    "    # Threshold 1.5 = 150% of normal volume\n",
    "    Insider_Catalyst_DF = apply_rvol_catalyst(target_df, rvol_threshold=1.5)\n",
    "\n",
    "    if not Insider_Catalyst_DF.empty:\n",
    "        # Sort by highest RVOL (Biggest Catalyst)\n",
    "        Insider_Catalyst_DF = Insider_Catalyst_DF.sort_values(\n",
    "            by=\"RVOL\", ascending=False\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        CATALYST_CSV = \"YfinanceDataDump/Insider_RVOL_Catalysts_USA.csv\"\n",
    "        Insider_Catalyst_DF.to_csv(CATALYST_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Catalyst candidates saved to '{CATALYST_CSV}'\")\n",
    "        print(\n",
    "            f\"Original Insider Count: {len(target_df)} -> Catalyst Count: {len(Insider_Catalyst_DF)}\"\n",
    "        )\n",
    "\n",
    "        # --- FIX IS HERE: Changed 'Price' to 'Current_Price' ---\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Current_Price\",\n",
    "            \"RVOL\",\n",
    "            \"Insider_Buys_Count\",\n",
    "            \"Net_Shares_Bought\",\n",
    "        ]\n",
    "\n",
    "        # Only add Analyst_Verdict if it actually exists in the dataframe\n",
    "        if \"Analyst_Verdict\" in Insider_Catalyst_DF.columns:\n",
    "            cols.append(\"Analyst_Verdict\")\n",
    "\n",
    "        print(\"\\n--- INSIDER STOCKS WITH HIGH VOLUME SPIKES ---\")\n",
    "        print(Insider_Catalyst_DF[cols].head(15))\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nRESULT: 0 stocks passed. No Insider picks are currently seeing high relative volume (>1.5x).\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Error: No Insider DataFrame found. Please run the Insider Scan cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb164c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scanning 220 stocks for Insider Buying...\n",
      "  Analyst Filter: 12 -> 10 stocks (Min Rating: Buy).\n",
      "\n",
      "  Final List: 10 stocks (Fortress + Insider Buying + Analyst Buy Rating)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 10. ANALYST FILTER FUNCTION FOR INSIDER PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(df_insiders, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if df_insiders.empty:\n",
    "        return df_insiders\n",
    "\n",
    "    tickers = df_insiders[\"Ticker\"].tolist()\n",
    "\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "\n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and \"recommendationMean\" in data:\n",
    "                    score = data.get(\"recommendationMean\")\n",
    "\n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append(\n",
    "                            {\n",
    "                                \"Ticker\": t,\n",
    "                                \"Analyst_Score\": score,\n",
    "                                \"Analyst_Verdict\": data.get(\"recommendationKey\", \"N/A\"),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "\n",
    "        if df_analyst.empty:\n",
    "            print(\" No Analyst ratings found for these tickers.\")\n",
    "            return df_insiders  # Return original if no data found\n",
    "\n",
    "        # Merge with the Insider DataFrame\n",
    "        merged = pd.merge(df_insiders, df_analyst, on=\"Ticker\", how=\"inner\")\n",
    "\n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged[\"Analyst_Score\"] <= max_score].copy()\n",
    "\n",
    "        print(\n",
    "            f\"  Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\"\n",
    "        )\n",
    "        return final_df.sort_values(by=\"Analyst_Score\", ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in Analyst Filter: {e}\")\n",
    "        return df_insiders\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    target_tickers = fortress_df[\"Ticker\"].tolist()\n",
    "else:\n",
    "    # Backup list just in case need to update periodically\n",
    "    target_tickers = [\n",
    "        \"PET.TO\",\n",
    "        \"MFI.TO\",\n",
    "        \"TXG.TO\",\n",
    "        \"SAP.TO\",\n",
    "        \"PAAS.TO\",\n",
    "        \"NEO.TO\",\n",
    "        \"WPM.TO\",\n",
    "        \"FNV.TO\",\n",
    "        \"LUG.TO\",\n",
    "        \"DPM.TO\",\n",
    "        \"ASM.TO\",\n",
    "        \"PNG.V\",\n",
    "        \"DSG.TO\",\n",
    "        \"KNT.TO\",\n",
    "        \"GGD.TO\",\n",
    "        \"GRGD.TO\",\n",
    "        \"WDO.TO\",\n",
    "        \"OGC.TO\",\n",
    "        \"DNG.TO\",\n",
    "        \"CLS.TO\",\n",
    "    ]\n",
    "\n",
    "# B. Run Insider Filter\n",
    "insider_winners = filter_for_insider_buying(target_tickers)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with Data Wrangler\n",
    "if not insider_winners.empty:\n",
    "    Fortress_insiders_Analyst_buy = filter_for_analyst_ratings(\n",
    "        insider_winners, max_score=2.5\n",
    "    )\n",
    "else:\n",
    "    Fortress_insiders_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_insiders_Analyst_buy.empty:\n",
    "    print(\n",
    "        f\"\\n  Final List: {len(Fortress_insiders_Analyst_buy)} stocks (Fortress + Insider Buying + Analyst Buy Rating)\"\n",
    "    )\n",
    "    Fortress_insiders_Analyst_buy.head()\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d999738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing EV/EBITDA for 220 Fortress stocks...\n",
      "\n",
      "--- SECTOR AVERAGES (EV/EBITDA) ---\n",
      "                Sector  Sector_Avg_EV_EBITDA\n",
      "       Basic Materials                 15.97\n",
      "Communication Services                 19.16\n",
      "     Consumer Cyclical                 14.37\n",
      "    Consumer Defensive                 15.98\n",
      "                Energy                  9.27\n",
      "            Healthcare                 20.85\n",
      "           Industrials                 20.93\n",
      "            Technology                 22.16\n",
      "\n",
      "Found 129 Undervalued Stocks\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: BURRY EV/EBITDA FILTER For Fortress Stocks\n",
    "# =============================================================================\n",
    "# EV/EBITDA is a valuation metric popular with hedge fund manager Michael Burry.\n",
    "#\n",
    "# EV = Enterprise Value = Market Cap + Debt - Cash\n",
    "#      (What it would cost to buy the whole company)\n",
    "#\n",
    "# EBITDA = Earnings Before Interest, Taxes, Depreciation, and Amortization\n",
    "#          (Proxy for operating cash flow)\n",
    "#\n",
    "# EV/EBITDA tells you how many years of cash flow it would take to buy the company.\n",
    "# Lower is better (cheaper stock).\n",
    "# We compare each stock to its SECTOR AVERAGE to find relative value.\n",
    "\n",
    "\n",
    "def filter_burry_ev_ebitda(df_input):\n",
    "    \"\"\"\n",
    "    Find stocks trading at a discount to their sector average.\n",
    "\n",
    "    Logic: A stock with EV/EBITDA of 8x is \"cheap\" in a sector\n",
    "           where the average is 15x.\n",
    "\n",
    "    Args:\n",
    "        df_input: DataFrame of stocks to analyze (usually fortress_df)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Stocks cheaper than their sector average\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\" Input DataFrame is empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Analyzing EV/EBITDA for {len(df_input)} Fortress stocks...\")\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "\n",
    "    # Fetch data in bulk\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        data = yq.get_modules(\"defaultKeyStatistics financialData summaryDetail\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ev_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            ticker_data = data.get(ticker, {})\n",
    "            if isinstance(ticker_data, str):\n",
    "                continue\n",
    "\n",
    "            stats = ticker_data.get(\"defaultKeyStatistics\", {})\n",
    "            fin_data = ticker_data.get(\"financialData\", {})\n",
    "            summary = ticker_data.get(\"summaryDetail\", {})\n",
    "\n",
    "            # Try to get pre-calculated EV/EBITDA\n",
    "            ev_ebitda = stats.get(\"enterpriseToEbitda\")\n",
    "\n",
    "            # If not available, calculate manually\n",
    "            if ev_ebitda is None:\n",
    "                try:\n",
    "                    market_cap = summary.get(\"marketCap\")\n",
    "                    total_debt = fin_data.get(\"totalDebt\")\n",
    "                    total_cash = fin_data.get(\"totalCash\")\n",
    "                    ebitda = fin_data.get(\"ebitda\")\n",
    "\n",
    "                    if all(\n",
    "                        v is not None\n",
    "                        for v in [market_cap, total_debt, total_cash, ebitda]\n",
    "                    ):\n",
    "                        if ebitda != 0:\n",
    "                            # EV = Market Cap + Debt - Cash\n",
    "                            enterprise_value = market_cap + total_debt - total_cash\n",
    "                            ev_ebitda = enterprise_value / ebitda\n",
    "                except:\n",
    "                    print(f\"Error calculating EV/EBITDA for {ticker}.\")\n",
    "                    pass\n",
    "\n",
    "            # Only include positive values (profitable companies)\n",
    "            if ev_ebitda is not None and ev_ebitda > 0:\n",
    "                ev_data.append({\"Ticker\": ticker, \"EV/EBITDA\": round(ev_ebitda, 2)})\n",
    "        except:\n",
    "            print(f\"Error processing {ticker}.\")\n",
    "            continue\n",
    "\n",
    "    df_vals = pd.DataFrame(ev_data)\n",
    "\n",
    "    if df_vals.empty:\n",
    "        print(\"Could not retrieve EV/EBITDA data.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Merge with sector data\n",
    "    merged_df = pd.merge(df_input, df_vals, on=\"Ticker\", how=\"inner\")\n",
    "\n",
    "    # Calculate sector averages\n",
    "    print(\"\\n--- SECTOR AVERAGES (EV/EBITDA) ---\")\n",
    "    sector_stats = merged_df.groupby(\"Sector\")[\"EV/EBITDA\"].mean().reset_index()\n",
    "    sector_stats.rename(columns={\"EV/EBITDA\": \"Sector_Avg_EV_EBITDA\"}, inplace=True)\n",
    "    sector_stats[\"Sector_Avg_EV_EBITDA\"] = sector_stats[\"Sector_Avg_EV_EBITDA\"].round(2)\n",
    "\n",
    "    print(sector_stats.to_string(index=False))\n",
    "\n",
    "    # Merge with sector averages\n",
    "    final_df = pd.merge(merged_df, sector_stats, on=\"Sector\", how=\"left\")\n",
    "\n",
    "    # Filter: Keep only stocks CHEAPER than sector average\n",
    "    burry_picks = final_df[\n",
    "        final_df[\"EV/EBITDA\"] < final_df[\"Sector_Avg_EV_EBITDA\"]\n",
    "    ].copy()\n",
    "\n",
    "    # Calculate discount percentage\n",
    "    # Discount = 1 - (Stock EV/EBITDA / Sector Average)\n",
    "    burry_picks[\"Discount_%\"] = round(\n",
    "        (1 - (burry_picks[\"EV/EBITDA\"] / burry_picks[\"Sector_Avg_EV_EBITDA\"])) * 100, 2\n",
    "    )\n",
    "\n",
    "    # Sort by biggest discount\n",
    "    burry_picks = burry_picks.sort_values(by=\"Discount_%\", ascending=False)\n",
    "\n",
    "    return burry_picks\n",
    "\n",
    "\n",
    "# Run the Burry filter\n",
    "if \"fortress_df\" in locals() and not fortress_df.empty:\n",
    "    Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "    if not Fortress_Burry_EV_EBITDA.empty:\n",
    "        print(f\"\\nFound {len(Fortress_Burry_EV_EBITDA)} Undervalued Stocks\")\n",
    "        Fortress_Burry_EV_EBITDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027324bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BURRY TECHNICALS: Analyzing 129 candidates ---\n",
      "\n",
      "SUCCESS: Technical picks saved to 'YfinanceDataDump/Burry_Technical_Picks_USA.csv'\n",
      "Original Undervalued Count: 129\n",
      "Survivors (Uptrend Only): 96\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11a: BURRY TECHNICAL SCAN (TREND + SQUEEZE)\n",
    "# =============================================================================\n",
    "# This combines two strategies into one efficient pass:\n",
    "# 1. SAFETY: Filters out downtrends (Price < 200 SMA).\n",
    "# 2. OPPORTUNITY: Calculates \"Volatility Squeeze\" to find coiling stocks.\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def apply_burry_technicals(df_input):\n",
    "    \"\"\"\n",
    "    Fetches 1y history ONCE.\n",
    "    Applies Trend Filter (Price > SMA200).\n",
    "    Calculates Squeeze Metrics (Bandwidth).\n",
    "    \"\"\"\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"   [Burry Technicals] Input DataFrame is empty. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    tickers = df_input[\"Ticker\"].tolist()\n",
    "    print(f\"\\n--- BURRY TECHNICALS: Analyzing {len(tickers)} candidates ---\")\n",
    "\n",
    "    # 1. Fetch History (1 Year is enough for both SMA200 and Squeeze)\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"   [Error] Failed to fetch history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    results_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Handle data structure\n",
    "            if len(tickers) > 1:\n",
    "                if ticker not in data.columns.levels[0]:\n",
    "                    continue\n",
    "                df_hist = data[ticker].copy()\n",
    "            else:\n",
    "                df_hist = data.copy()\n",
    "\n",
    "            # Need sufficient data\n",
    "            if len(df_hist) < 200:\n",
    "                print(f\"   [Skipping] {ticker}: Insufficient history (<200 days).\")\n",
    "                continue\n",
    "\n",
    "            # --- METRIC 1: TREND (SMA 200) ---\n",
    "            sma_200 = df_hist[\"Close\"].rolling(window=200).mean().iloc[-1]\n",
    "            current_price = df_hist[\"Close\"].iloc[-1]\n",
    "\n",
    "            # HARD FILTER: Must be in Uptrend\n",
    "            if current_price < sma_200:\n",
    "                continue\n",
    "\n",
    "            dist_sma_pct = ((current_price - sma_200) / sma_200) * 100\n",
    "\n",
    "            # --- METRIC 2: SQUEEZE (Bollinger Bands) ---\n",
    "            sma_20 = df_hist[\"Close\"].rolling(window=20).mean()\n",
    "            std_20 = df_hist[\"Close\"].rolling(window=20).std()\n",
    "\n",
    "            upper = sma_20 + (2 * std_20)\n",
    "            lower = sma_20 - (2 * std_20)\n",
    "            bandwidth = (upper - lower) / sma_20\n",
    "\n",
    "            # Check Squeeze Status (Lowest 15% of last 6 months)\n",
    "            recent_bw = bandwidth.tail(126)  # ~6 months\n",
    "            current_bw = recent_bw.iloc[-1]\n",
    "            squeeze_threshold = recent_bw.quantile(0.15)\n",
    "            is_squeezing = current_bw <= squeeze_threshold\n",
    "\n",
    "            # --- COMPILE RESULT ---\n",
    "            # Get base fundamental data\n",
    "            base_row = df_input[df_input[\"Ticker\"] == ticker].iloc[0].to_dict()\n",
    "\n",
    "            # Add Technical Data\n",
    "            base_row[\"Price\"] = round(current_price, 2)\n",
    "            base_row[\"SMA_200\"] = round(sma_200, 2)\n",
    "            base_row[\"Trend_Dist_%\"] = round(dist_sma_pct, 2)\n",
    "            base_row[\"Bandwidth_%\"] = round(current_bw * 100, 2)\n",
    "            base_row[\"In_Squeeze\"] = \"YES\" if is_squeezing else \"No\"\n",
    "\n",
    "            results_data.append(base_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   [Error] Processing {ticker}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results_data)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# EXECUTION\n",
    "# =========================================\n",
    "\n",
    "if \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "\n",
    "    # Run the consolidated scan\n",
    "    Burry_Technicals_DF = apply_burry_technicals(Fortress_Burry_EV_EBITDA)\n",
    "\n",
    "    if not Burry_Technicals_DF.empty:\n",
    "        # Sort by \"Squeeziness\" (Bandwidth), but favor those in Squeeze first\n",
    "        # We sort by In_Squeeze (descending, so YES comes first) then Bandwidth (ascending)\n",
    "        Burry_Technicals_DF = Burry_Technicals_DF.sort_values(\n",
    "            by=[\"In_Squeeze\", \"Bandwidth_%\"], ascending=[False, True]\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        TECH_CSV = \"YfinanceDataDump/Burry_Technical_Picks_USA.csv\"\n",
    "        Burry_Technicals_DF.to_csv(TECH_CSV, index=False)\n",
    "\n",
    "        print(f\"\\nSUCCESS: Technical picks saved to '{TECH_CSV}'\")\n",
    "        print(f\"Original Undervalued Count: {len(Fortress_Burry_EV_EBITDA)}\")\n",
    "        print(f\"Survivors (Uptrend Only): {len(Burry_Technicals_DF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efa7b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing EV/EBITDA for 220 Fortress stocks...\n",
      "\n",
      "--- SECTOR AVERAGES (EV/EBITDA) ---\n",
      "                Sector  Sector_Avg_EV_EBITDA\n",
      "       Basic Materials                 15.97\n",
      "Communication Services                 19.16\n",
      "     Consumer Cyclical                 14.37\n",
      "    Consumer Defensive                 15.98\n",
      "                Energy                  9.27\n",
      "            Healthcare                 20.85\n",
      "           Industrials                 20.93\n",
      "            Technology                 22.16\n",
      "Analyst Filter: 125 -> 104 stocks (Min Rating: Buy).\n",
      "\n",
      "Final List: 104 stocks (Fortress + Burry + Analyst Buy Rating)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 12. ANALYST FILTER FUNCTION FOR Burry EV/EBITDA PICKS (NEW)\n",
    "# ==========================================\n",
    "def filter_for_analyst_ratings(Fortress_Burry_EV_EBITDA, max_score=2.5):\n",
    "    \"\"\"\n",
    "    Fetches analyst data for the insider winners and filters for 'Buy' or better.\n",
    "    Scale: 1.0 = Strong Buy, 5.0 = Sell.\n",
    "    Cutoff: 2.5 ensures we get 'Buy' and 'Strong Buy'.\n",
    "    \"\"\"\n",
    "    if Fortress_Burry_EV_EBITDA.empty:\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "    tickers = Fortress_Burry_EV_EBITDA[\"Ticker\"].tolist()\n",
    "\n",
    "    try:\n",
    "        yq = Ticker(tickers, asynchronous=True)\n",
    "        # 'financial_data' contains the specific recommendation scores\n",
    "        fin_data = yq.financial_data\n",
    "\n",
    "        analyst_data = []\n",
    "        for t in tickers:\n",
    "            # Check if we got valid data for this ticker\n",
    "            if isinstance(fin_data, dict) and t in fin_data:\n",
    "                data = fin_data[t]\n",
    "                # Ensure it's a dictionary and has the key we need\n",
    "                if isinstance(data, dict) and \"recommendationMean\" in data:\n",
    "                    score = data.get(\"recommendationMean\")\n",
    "\n",
    "                    # Only keep valid scores (sometimes they are None)\n",
    "                    if score is not None:\n",
    "                        analyst_data.append(\n",
    "                            {\n",
    "                                \"Ticker\": t,\n",
    "                                \"Analyst_Score\": score,\n",
    "                                \"Analyst_Verdict\": data.get(\"recommendationKey\", \"N/A\"),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "        df_analyst = pd.DataFrame(analyst_data)\n",
    "\n",
    "        if df_analyst.empty:\n",
    "            print(\"No Analyst ratings found for these tickers.\")\n",
    "            return Fortress_Burry_EV_EBITDA  # Return original if no data found\n",
    "\n",
    "        # Merge with the Fortress DataFrame\n",
    "        merged = pd.merge(\n",
    "            Fortress_Burry_EV_EBITDA, df_analyst, on=\"Ticker\", how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # FILTER: Keep only scores <= max_score (Lower is better)\n",
    "        final_df = merged[merged[\"Analyst_Score\"] <= max_score].copy()\n",
    "\n",
    "        print(\n",
    "            f\"Analyst Filter: {len(merged)} -> {len(final_df)} stocks (Min Rating: Buy).\"\n",
    "        )\n",
    "        return final_df.sort_values(by=\"Analyst_Score\", ascending=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Analyst Filter: {e}\")\n",
    "        return Fortress_Burry_EV_EBITDA\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "# A. Setup Tickers\n",
    "if \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    target_tickers = Fortress_Burry_EV_EBITDA[\"Ticker\"].tolist()\n",
    "\n",
    "\n",
    "# B. Run Insider Filter\n",
    "Fortress_Burry_EV_EBITDA = filter_burry_ev_ebitda(fortress_df)\n",
    "\n",
    "# C. Run Analyst Filter (NEW STEP)\n",
    "# We overwrite 'Fortress_insiders' so it works with Data Wrangler\n",
    "if not Fortress_Burry_EV_EBITDA.empty:\n",
    "    Fortress_Burry_Analyst_buy = filter_for_analyst_ratings(\n",
    "        Fortress_Burry_EV_EBITDA, max_score=2.5\n",
    "    )\n",
    "else:\n",
    "    Fortress_Burry_Analyst_buy = pd.DataFrame()\n",
    "\n",
    "# D. Display Result\n",
    "if not Fortress_Burry_Analyst_buy.empty:\n",
    "    print(\n",
    "        f\"\\nFinal List: {len(Fortress_Burry_Analyst_buy)} stocks (Fortress + Burry + Analyst Buy Rating)\"\n",
    "    )\n",
    "    Fortress_Burry_Analyst_buy.head()\n",
    "else:\n",
    "    print(\"No stocks passed all filters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc57c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEEP VALUE GEMS FOUND: 2\n",
      "============================================================\n",
      "Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 13. THE \"DEEP VALUE\" INTERSECTION (Buffett + Burry)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Ensure we have the Buffett Data\n",
    "if \"Buffett_Value_DF\" not in locals():\n",
    "    print(\"Buffett Data not found. Running scan now...\")\n",
    "    if \"get_buffett_value_picks\" in globals() and \"final_results\" in locals():\n",
    "        Buffett_Value_DF = get_buffett_value_picks(final_results)\n",
    "    else:\n",
    "        print(\"Missing 'final_results' or 'get_buffett_value_picks' function.\")\n",
    "        Buffett_Value_DF = pd.DataFrame()\n",
    "\n",
    "# 2. Ensure we have the Burry Data\n",
    "if \"Fortress_Burry_EV_EBITDA\" not in locals():\n",
    "    print(\"Please run the Burry EV/EBITDA filter cell first.\")\n",
    "    Fortress_Burry_EV_EBITDA = pd.DataFrame()\n",
    "\n",
    "# 3. THE MERGE (Finding the Overlap)\n",
    "if not Buffett_Value_DF.empty and not Fortress_Burry_EV_EBITDA.empty:\n",
    "\n",
    "    # Merge on Ticker to find stocks that appear in BOTH lists\n",
    "    # We use an 'inner' join, which means \"keep only if in both\"\n",
    "    Deep_Value_Intersection = pd.merge(\n",
    "        Buffett_Value_DF[[\"Ticker\", \"P/B Ratio\", \"ROE %\", \"Debt/Eq %\"]],\n",
    "        Fortress_Burry_EV_EBITDA[\n",
    "            [\n",
    "                \"Ticker\",\n",
    "                \"Price\",\n",
    "                \"Sector\",\n",
    "                \"EV/EBITDA\",\n",
    "                \"Sector_Avg_EV_EBITDA\",\n",
    "                \"Discount_%\",\n",
    "                \"Tier\",\n",
    "            ]\n",
    "        ],\n",
    "        on=\"Ticker\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    if not Deep_Value_Intersection.empty:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"DEEP VALUE GEMS FOUND: {len(Deep_Value_Intersection)}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\n",
    "            \"Criteria: Trading < Book Value (Buffett) AND Cheaper than Sector (Burry)\"\n",
    "        )\n",
    "\n",
    "        # Sort by the \"Discount\" (how cheap they are vs sector)\n",
    "        Deep_Value_Intersection = Deep_Value_Intersection.sort_values(\n",
    "            by=\"Discount_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Tier\",\n",
    "            \"P/B Ratio\",\n",
    "            \"EV/EBITDA\",\n",
    "            \"Sector_Avg_EV_EBITDA\",\n",
    "            \"Discount_%\",\n",
    "            \"Sector\",\n",
    "        ]\n",
    "        Deep_Value_Intersection[cols].head(5)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n No stocks passed BOTH filters.\")\n",
    "        print(\n",
    "            \"This means no stock is both 'Below Book Value' AND 'Cheaper than Sector Average' at the same time.\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Buffett Count: {len(Buffett_Value_DF)} | Burry Count: {len(Fortress_Burry_EV_EBITDA)}\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\"Cannot combine. One of the filters returned 0 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dcc4d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Analyst-Vetted Insider List.\n",
      "Using Analyst-Vetted Burry List.\n",
      "\n",
      "============================================================\n",
      "HIGH CONVICTION WINNERS FOUND: 8\n",
      "============================================================\n",
      "Criteria: Cheap vs Sector (Burry) + Insider Buying\n",
      "\n",
      "Saved to: YfinanceDataDump\\High_Conviction_Picks_USA.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: THE \"HIGH CONVICTION\" INTERSECTION (BURRY + INSIDERS)\n",
    "# =============================================================================\n",
    "# This finds stocks that are BOTH:\n",
    "# 1. Undervalued vs their Sector (Burry EV/EBITDA)\n",
    "# 2. Being accumulated by Insiders (Insider Confidence)\n",
    "#\n",
    "# This is a powerful \"Anti-Value Trap\" filter. Insiders rarely buy\n",
    "# sinking ships, even if they look cheap on paper.\n",
    "\n",
    "# --- 1. DETECT BEST AVAILABLE DATAFRAMES ---\n",
    "\n",
    "# Try to find the Insider list (preferring the one with Analyst ratings if available)\n",
    "if (\n",
    "    \"Fortress_insiders_Analyst_buy\" in locals()\n",
    "    and not Fortress_insiders_Analyst_buy.empty\n",
    "):\n",
    "    df_insider_source = Fortress_insiders_Analyst_buy\n",
    "    print(\"Using Analyst-Vetted Insider List.\")\n",
    "elif \"Fortress_insiders\" in locals() and not Fortress_insiders.empty:\n",
    "    df_insider_source = Fortress_insiders\n",
    "    print(\"Using Raw Insider List (No Analyst Check).\")\n",
    "else:\n",
    "    df_insider_source = pd.DataFrame()\n",
    "    print(\"Warning: No Insider data found.\")\n",
    "\n",
    "# Try to find the Burry list (preferring the one with Analyst ratings if available)\n",
    "if \"Fortress_Burry_Analyst_buy\" in locals() and not Fortress_Burry_Analyst_buy.empty:\n",
    "    df_burry_source = Fortress_Burry_Analyst_buy\n",
    "    print(\"Using Analyst-Vetted Burry List.\")\n",
    "elif \"Fortress_Burry_EV_EBITDA\" in locals() and not Fortress_Burry_EV_EBITDA.empty:\n",
    "    df_burry_source = Fortress_Burry_EV_EBITDA\n",
    "    print(\"Using Raw Burry List (No Analyst Check).\")\n",
    "else:\n",
    "    df_burry_source = pd.DataFrame()\n",
    "    print(\"Warning: No Burry EV/EBITDA data found.\")\n",
    "\n",
    "# --- 2. PERFORM THE INTERSECTION ---\n",
    "\n",
    "if not df_insider_source.empty and not df_burry_source.empty:\n",
    "\n",
    "    # We merge on 'Ticker'. 'inner' means keep only stocks found in BOTH lists.\n",
    "    # We use suffixes=('', '_drop') to handle duplicate columns (like Price)\n",
    "    high_conviction_df = pd.merge(\n",
    "        df_burry_source[\n",
    "            [\n",
    "                \"Ticker\",\n",
    "                \"Price\",\n",
    "                \"Sector\",\n",
    "                \"Tier\",\n",
    "                \"EV/EBITDA\",\n",
    "                \"Sector_Avg_EV_EBITDA\",\n",
    "                \"Discount_%\",\n",
    "            ]\n",
    "        ],\n",
    "        df_insider_source[[\"Ticker\", \"Insider_Buys_Count\", \"Net_Shares_Bought\"]],\n",
    "        on=\"Ticker\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    if not high_conviction_df.empty:\n",
    "        # Sort by Discount % (Deepest value first)\n",
    "        high_conviction_df = high_conviction_df.sort_values(\n",
    "            by=\"Discount_%\", ascending=False\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"HIGH CONVICTION WINNERS FOUND: {len(high_conviction_df)}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Criteria: Cheap vs Sector (Burry) + Insider Buying\")\n",
    "\n",
    "        # Reorder columns for readability\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Sector\",\n",
    "            \"Tier\",\n",
    "            \"Discount_%\",\n",
    "            \"EV/EBITDA\",\n",
    "            \"Insider_Buys_Count\",\n",
    "            \"Net_Shares_Bought\",\n",
    "        ]\n",
    "\n",
    "        # Display nicely\n",
    "        high_conviction_df[cols].head()\n",
    "\n",
    "        # Optional: Save to CSV\n",
    "        save_path = os.path.join(DATA_FOLDER, \"High_Conviction_Picks_USA.csv\")\n",
    "        high_conviction_df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nSaved to: {save_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nNo overlap found. No stock is both 'Cheap vs Sector' AND 'Insider Buy' target.\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Burry Count: {len(df_burry_source)} | Insider Count: {len(df_insider_source)}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\nCannot run intersection. Missing one or both source lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 12 stocks ---\n",
      "1. Fetching Analyst Ratings from Finviz...\n",
      "2. Fetching Price & Volatility from yfinance...\n",
      "\n",
      "--- Final Watchlist ---\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Watchlist Combiner (Finviz + YFinance)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. INPUT YOUR MANUAL LIST HERE ---\n",
    "MY_TICKERS = [\n",
    "    \"SHLS\",\n",
    "    \"BANC\",\n",
    "    \"ONB\",\n",
    "    \"UBER\",\n",
    "    \"ADMA\",\n",
    "    \"MIR\",\n",
    "    \"APG\",\n",
    "    \"SEI\",\n",
    "    \"FLEX\",\n",
    "    \"DD\",\n",
    "    \"SVM\",\n",
    "    \"GIL\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_combined_watchlist(ticker_list):\n",
    "    print(f\"--- Processing {len(ticker_list)} stocks ---\")\n",
    "\n",
    "    # --- PART A: Get Analyst Ratings from Finviz ---\n",
    "    print(\"1. Fetching Analyst Ratings from Finviz...\")\n",
    "    finviz_data = []\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = finvizfinance(ticker)\n",
    "            info = stock.ticker_fundament()\n",
    "\n",
    "            finviz_data.append(\n",
    "                {\n",
    "                    \"Ticker\": ticker,\n",
    "                    \"Recom\": info.get(\"Recom\", np.nan),\n",
    "                    \"Target_Price\": info.get(\"Target Price\", np.nan),\n",
    "                }\n",
    "            )\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping Finviz for {ticker}: {e}\")\n",
    "            finviz_data.append(\n",
    "                {\"Ticker\": ticker, \"Recom\": np.nan, \"Target_Price\": np.nan}\n",
    "            )\n",
    "\n",
    "    df_finviz = pd.DataFrame(finviz_data)\n",
    "\n",
    "    # --- PART B: Get Real-Time Stats from yfinance ---\n",
    "    print(\"2. Fetching Price & Volatility from yfinance...\")\n",
    "\n",
    "    try:\n",
    "        # Download data (1 Year is perfect for 52-Week MA)\n",
    "        data = yf.download(\n",
    "            ticker_list,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            group_by=\"ticker\",\n",
    "            progress=False,\n",
    "            threads=True,\n",
    "        )\n",
    "        yf_stats = []\n",
    "\n",
    "        for ticker in ticker_list:\n",
    "            try:\n",
    "                # --- FIXED: Robust Data Extraction ---\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    if ticker in data.columns.levels[0]:\n",
    "                        df = data[ticker].copy()\n",
    "                    else:\n",
    "                        print(f\"   Warning: {ticker} not found in yfinance download.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    df = data.copy()\n",
    "\n",
    "                # Cleanup\n",
    "                df = df.dropna(subset=[\"Close\"])\n",
    "                if len(df) < 20:\n",
    "                    print(f\"   Warning: Not enough data for {ticker}\")\n",
    "                    continue\n",
    "\n",
    "                # --- MATH CALCULATIONS ---\n",
    "                current_price = df[\"Close\"].iloc[-1]\n",
    "                prev_close = df[\"Close\"].iloc[-2]\n",
    "\n",
    "                high_52 = df[\"High\"].max()\n",
    "                drop_from_high = ((current_price - high_52) / high_52) * 100\n",
    "\n",
    "                change_pct = ((current_price - prev_close) / prev_close) * 100\n",
    "\n",
    "                # Volatility (30-day Std Dev)\n",
    "                volatility = df[\"Close\"].pct_change().std() * 100\n",
    "\n",
    "                # Relative Volume\n",
    "                curr_vol = df[\"Volume\"].iloc[-1]\n",
    "                avg_vol = df[\"Volume\"].tail(30).mean()\n",
    "                rel_vol = curr_vol / avg_vol if avg_vol > 0 else 0\n",
    "\n",
    "                # --- NEW: 52-Week Moving Average ---\n",
    "                # Since we fetched exactly 1 year ('1y'), the mean of the whole column is the 52W MA\n",
    "                ma_52w = df[\"Close\"].mean()\n",
    "\n",
    "                # Distance from MA (Optional but helpful metric)\n",
    "                # dist_ma = ((current_price - ma_52w) / ma_52w) * 100\n",
    "\n",
    "                yf_stats.append(\n",
    "                    {\n",
    "                        \"Ticker\": ticker,\n",
    "                        \"Price\": round(current_price, 2),\n",
    "                        \"Change_%\": round(change_pct, 2),\n",
    "                        \"52W_MA\": round(ma_52w, 2),  # <--- Added Here\n",
    "                        \"Drop_from_High_%\": round(drop_from_high, 2),\n",
    "                        \"Volatility_%\": round(volatility, 2),\n",
    "                        \"Rel_Volume\": round(rel_vol, 2),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating stats for {ticker}: {e}\")\n",
    "                continue\n",
    "\n",
    "        df_yf = pd.DataFrame(yf_stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"yfinance Critical Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- PART C: Merge ---\n",
    "    if not df_finviz.empty:\n",
    "        if not df_yf.empty:\n",
    "            master_df = pd.merge(df_finviz, df_yf, on=\"Ticker\", how=\"outer\")\n",
    "        else:\n",
    "            master_df = df_finviz\n",
    "\n",
    "        # Added '52W_MA' to this list so it displays in the final table\n",
    "        cols = [\n",
    "            \"Ticker\",\n",
    "            \"Price\",\n",
    "            \"Change_%\",\n",
    "            \"52W_MA\",\n",
    "            \"Drop_from_High_%\",\n",
    "            \"Recom\",\n",
    "            \"Target_Price\",\n",
    "            \"Rel_Volume\",\n",
    "            \"Volatility_%\",\n",
    "        ]\n",
    "\n",
    "        final_cols = [c for c in cols if c in master_df.columns]\n",
    "        return master_df[final_cols]\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- RUN IT ---\n",
    "watchlist_df = get_combined_watchlist(MY_TICKERS)\n",
    "\n",
    "if not watchlist_df.empty:\n",
    "    if \"Drop_from_High_%\" in watchlist_df.columns:\n",
    "        watchlist_df[\"Drop_from_High_%\"] = pd.to_numeric(\n",
    "            watchlist_df[\"Drop_from_High_%\"], errors=\"coerce\"\n",
    "        )\n",
    "        print(\"\\n--- Final Watchlist ---\")\n",
    "        watchlist_df.sort_values(by=\"Drop_from_High_%\", ascending=True).head()\n",
    "    else:\n",
    "        watchlist_df.head()\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc2bed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded securely.\n",
      "\n",
      "Gemini 3 is thinking (High Reasoning Mode)... analyzing $['SHLS']...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The following Market Sentiment Analysis for **Shoals Technologies Group, Inc. (SHLS)** evaluates the company's standing as of **January 20, 2026**, incorporating the latest search data from the last 30 days.\n",
       "\n",
       "## Gemini Sentiment Report: ['SHLS']\n",
       "**Reasoning Depth:** High\n",
       "**Sentiment Score:** 6.5/10\n",
       "**Verdict:** **Speculative Buy**\n",
       "\n",
       "### 1. The Bull Thesis\n",
       "*   **Record Backlog & Growth:** As of Q3 2025, SHLS reported a record backlog and awarded orders of **$720.9 million** (up 21% YoY). This provides high revenue visibility for 2026 despite earlier headwinds.\n",
       "*   **Sector Tailwind:** In early January 2026, the solar sector experienced a broad \"risk-on\" rotation, lifting peers like Canadian Solar (CSIQ) and Enphase (ENPH). SHLS rallied **~11-12%** in sympathy, suggesting it is a high-beta beneficiary of improving macro sentiment (likely tied to interest rate expectations).\n",
       "*   **Institutional Accumulation:** Recent 13F filings show significant accumulation by \"smart money.\" Voya Investment Management increased its position by nearly **2,000%** and Swedbank by **200%** in late 2025, signaling institutional confidence in a turnaround.\n",
       "*   **IP Reinforcement:** Despite losing the initial ITC battle in early 2025, SHLS has aggressively filed complaints using *new* patents ('375 and '376) to rebuild its legal moat against competitors like Voltage, LLC.\n",
       "\n",
       "### 2. The Bear Thesis\n",
       "*   **The \"Broken Moat\" Risk:** The major bearish catalyst remains the **ITC's reversal in January 2025**, which found \"no violation\" by competitor Voltage, LLC regarding the key '153 patent. This legally allows competitors to market similar \"trunk bus\" solutions, effectively piercing SHLS's monopoly-like patent protection until new litigation succeeds.\n",
       "*   **Insider Selling:** Contrary to retail \"whispers\" of insider buying, actual SEC filings from **December 2025** show *selling*. CFO Dominic Bardos and President Jeffery Tolnar sold shares, which often dampens momentum and contradicts the \"undervalued\" narrative.\n",
       "*   **Execution Misses:** The company missed EPS estimates in Q3 2025 ($0.07 vs. $0.13 expected), creating a \"show me\" story where investors demand perfect execution on margins before re-rating the stock higher.\n",
       "\n",
       "### 3. Deep Dive Analysis\n",
       "\n",
       "#### **News Virality & Psychology**\n",
       "*   **Current Mood:** **Cautiously Optimistic.** The headlines in Jan 2026 are dominated by price action (\"Trading 11.2% Higher\") rather than fundamental news. This indicates a \"relief rally\" or short-covering event driven by macro factors rather than a specific company catalyst.\n",
       "*   **The Narrative Shift:** The conversation has shifted from \"Litigation Panic\" (early 2025) to \"Backlog Execution\" (2026). The market seems to be pricing in the competitive threat from Voltage but betting that the total addressable market (TAM) expansion will lift all boats.\n",
       "\n",
       "#### **Smart Money & Institutional Flows**\n",
       "*   **Institutions:** **Net Buyers.** The massive position increases by Voya and Swedbank suggest that funds viewed the 2025 dip as a buying opportunity. The \"Fund Sentiment Score\" remains high.\n",
       "*   **Insiders:** **Net Sellers.** The recent sales in Dec 2025 by top executives (CFO, President) are a red flag. While these may be tax-related or routine, they signal that management is not aggressively buying the dip at these levels.\n",
       "\n",
       "#### **Litigation Update (Crucial Context)**\n",
       "*   **Status:** **Defensive.**\n",
       "    *   **Jan 2025:** ITC rules *against* SHLS (finding no violation by Voltage).\n",
       "    *   **Feb 2025:** SHLS appeals to the Federal Circuit.\n",
       "    *   **Current (Jan 2026):** SHLS is relying on *newly issued* patents to file fresh complaints. Investors must understand that the original \"impenetrable\" IP moat is currently compromised, making the stock more dependent on execution than patent protection.\n",
       "\n",
       "#### **The \"Whisper\" Number**\n",
       "*   **Retail Sentiment:** **Bullish.** Forums (Stocktwits, Reddit) are circulating a \"catch-up trade\" narrative, targeting **$12-$15**. Traders are focused on the high short interest and the stock's lag behind peers.\n",
       "*   **Consensus Disconnect:** Retail traders are ignoring the insider selling, focusing instead on the \"buyback\" narrative (which is older news).\n",
       "\n",
       "### 4. Conclusion\n",
       "Shoals Technologies Group (SHLS) is a **high-risk, high-reward play** for early 2026. The company is successfully growing its order book and expanding internationally (e.g., Chile), which supports the **Bull Case**. However, the **Bear Case** is structural: the loss of its absolute patent monopoly means it must now compete on price and efficiency rather than legal exclusivity.\n",
       "\n",
       "**Verdict:** The stock is a **Speculative Buy** for investors betting on a solar sector recovery. The heavy institutional buying provides a floor, but the recent insider selling and legal overhang suggest upside may be capped until the company delivers a \"beat-and-raise\" quarter to prove its competitive durability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " INTERACTIVE SESSION: Ask follow-ups about ['SHLS']\n",
      " Type 'exit' or 'quit' to stop.\n",
      "==================================================\n",
      "\n",
      "Ending session.\n"
     ]
    }
   ],
   "source": [
    "tickers_gemini = [\"SHLS\"]\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ==========================================\n",
    "# Senior Analyst with INTERACTIVE FOLLOW-UPS\n",
    "# ==========================================\n",
    "\n",
    "KEY_FILE_PATH = (\n",
    "    r\"C:\\Users\\jdcc3\\OneDrive - McMaster University\\Gemini API Key\\gemini_key.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_api_key(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading key file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "api_key = load_api_key(KEY_FILE_PATH)\n",
    "\n",
    "if api_key:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    print(\"API Key loaded securely.\")\n",
    "else:\n",
    "    print(\"CRITICAL: API Key not loaded.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# INTERACTIVE ANALYSIS FUNCTION\n",
    "# ==========================================\n",
    "def analyze_and_chat_gemini_3(tickers_gemini, company_name=None):\n",
    "\n",
    "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
    "        print(\"Stop: No API Key found.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\nGemini 3 is thinking (High Reasoning Mode)... analyzing ${tickers_gemini}...\"\n",
    "    )\n",
    "\n",
    "    # 1. Initialize Client\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    # 2. Configure the Chat with Tools (Search) and Reasoning\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=False, thinking_level=\"HIGH\"\n",
    "        ),\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        response_modalities=[\"TEXT\"],\n",
    "    )\n",
    "\n",
    "    # 3. Create the Chat Session (This holds the history)\n",
    "    chat = client.chats.create(\n",
    "        model=\"gemini-3-pro-preview\", config=config  # Recommended for reasoning + speed\n",
    "    )\n",
    "\n",
    "    # 4. Define the Initial Prompt\n",
    "    initial_prompt = f\"\"\"\n",
    "    You are a Senior Equity Research Analyst using the Gemini 3 Reasoning Engine. \n",
    "    Perform a deep \"Market Sentiment Analysis\" on {tickers_gemini}.\n",
    "    \n",
    "    Step 1: SEARCH. Use Google Search to find the latest (last 30 days) news, analyst notes, and SEC filings.\n",
    "    Step 2: REASON. Analyze the search results to determine the true market psychology.\n",
    "    \n",
    "    Investigate these 4 Pillars:\n",
    "    1. **News Virality**: Are headlines fear-mongering or euphoric?\n",
    "    2. **Analyst Shifts**: Are price targets moving UP or DOWN?\n",
    "    3. **Institutional Flows**: Hedge funds or insiders buying/selling?\n",
    "    4. **The \"Whisper\" Number**: What are traders saying on forums?\n",
    "\n",
    "    **OUTPUT FORMAT:**\n",
    "    Produce a professional Markdown report:\n",
    "    \n",
    "    ## Gemini Sentiment Report: {tickers_gemini}\n",
    "    **Reasoning Depth:** High\n",
    "    **Sentiment Score:** [1-10]\n",
    "    **Verdict:** [Buy / Hold / Sell / Speculative]\n",
    "    \n",
    "    ### 1. The Bull Thesis\n",
    "    * ...\n",
    "    \n",
    "    ### 2. The Bear Thesis\n",
    "    * ...\n",
    "    \n",
    "    ### 3. Deep Dive Analysis\n",
    "    * **News Analysis**: ...\n",
    "    * **Smart Money**: ...\n",
    "    * **Financial Statement Analysis**: (Historic performance last 3y + outlook)\n",
    "    \n",
    "    ### 4. Conclusion\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # 5. Send Initial Request\n",
    "        response = chat.send_message(initial_prompt)\n",
    "        display(Markdown(response.text))\n",
    "\n",
    "        # ==========================================\n",
    "        # NEW: INTERACTIVE LOOP\n",
    "        # ==========================================\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\" INTERACTIVE SESSION: Ask follow-ups about {tickers_gemini}\")\n",
    "        print(\" Type 'exit' or 'quit' to stop.\")\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_question = input(\"\\nYour Question type stop to close this prompt: \")\n",
    "\n",
    "            # Check for exit condition\n",
    "            if user_question.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "                print(\"Ending session.\")\n",
    "                break\n",
    "\n",
    "            # Send follow-up to the SAME chat session\n",
    "            print(\"Analyzing...\")\n",
    "            follow_up_response = chat.send_message(user_question)\n",
    "            display(Markdown(follow_up_response.text))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    analyze_and_chat_gemini_3(tickers_gemini, tickers_gemini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
